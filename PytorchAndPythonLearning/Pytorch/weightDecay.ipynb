{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 权重衰减\n",
    "过拟合可以通过收集更多的训练数据来缓解过拟合，但是获取更多的数据会导致成本很高。\n",
    "\n",
    "如果有了很多高质量的数据，那么我们可以将重点放在正则化技术上。\n",
    "\n",
    "在[多项式回归](./overfittingAndUnderfitting.ipynb)中，我们通过限制特征的数量来缓解过拟合。但是这种简单地丢弃特征的行为太过于生硬。\n",
    "\n",
    "在训练参数化机器学习模型的时候，权重衰减（weight decay）是广泛使用的正则化技术之一，通常被称为L2正则化，通过函数与0的距离来衡量函数的复杂度。\n",
    "\n",
    "一种简单的方法是通过线性函数中权重向量的某个范数来度量复杂性，要保证权重向量比较小， 最常用方法是将其范数作为惩罚项加到最小化损失的问题中。 将原来的训练目标最小化训练标签上的预测损失， 调整为最小化预测损失和惩罚项之和。\n",
    "\n",
    "**为什么可以防止过拟合呢？**\n",
    "1. 从模型的复杂度上解释：更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合更好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。\n",
    "2. 从数学方面的解释：过拟合的时候，拟合函数的系数往往非常大，在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from pltutils import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w,true_b=t.ones((200))*0.01,0.05\n",
    "X= t.normal(0,1,size=(20+100,200))\n",
    "Y=t.zeros((120,1))\n",
    "for i in range(100+20):\n",
    "    Y[i]=true_b+(X[i]*true_w).sum()+t.normal(0,0.01,(1,))\n",
    "\n",
    "\n",
    "def data_iter(batch_size: int, features: t.Tensor, labels: t.Tensor):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = t.tensor(\n",
    "            indices[i:min(i+batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netwrok architecture\n",
    "def init_params():\n",
    "    w=t.normal(0,1,size=(200,1),requires_grad=True)\n",
    "    b=t.zeros(1,requires_grad=True)\n",
    "    return [w,b]\n",
    "# l2 penalty for weights\n",
    "def l2_penalty(w:t.Tensor):\n",
    "    return t.sum(w.pow(2))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "def stochastic_gradient_desent(params: t.Tensor, lr, batch_size):\n",
    "    with t.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr*param.grad/batch_size\n",
    "            param.grad.zero_()\n",
    "# training function\n",
    "def train(lambd):\n",
    "    w,b=init_params()\n",
    "    for epoch in range(200):\n",
    "        train_iter = data_iter(1, X[:20], Y[:20])\n",
    "        test_iter = data_iter(1, X[20:], Y[20:])\n",
    "        total_train_loss =[]\n",
    "        total_eval_loss=[]\n",
    "        for x,y in train_iter:\n",
    "            loss = t.pow((y - (t.mm(x, w)+b)), 2).mean()\n",
    "            loss+=lambd*l2_penalty(w)\n",
    "            loss.sum().backward()\n",
    "            stochastic_gradient_desent([w,b],lr=0.003,batch_size=5)\n",
    "            total_train_loss.append(loss.item())\n",
    "        for x,y in test_iter:\n",
    "            #print(x.shape, w.shape, t.mm(x, w).shape)\n",
    "            loss = t.pow((y - (t.mm(x,w)+b)), 2).mean()\n",
    "            total_eval_loss.append(loss.item())\n",
    "            \n",
    "        print(\n",
    "            f\"epoch:{epoch} eval_loss = {np.mean(total_eval_loss)},train_loss = {np.mean(total_train_loss)}\")\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 eval_loss = 217.56593918681145,train_loss = 199.9007263660431\n",
      "epoch:1 eval_loss = 210.50795641635546,train_loss = 116.10138123072684\n",
      "epoch:2 eval_loss = 205.7486390982784,train_loss = 68.48893291950226\n",
      "epoch:3 eval_loss = 202.67142190419136,train_loss = 41.09773392267525\n",
      "epoch:4 eval_loss = 200.64495701316744,train_loss = 25.04750501215458\n",
      "epoch:5 eval_loss = 199.2305720605579,train_loss = 15.467374025445315\n",
      "epoch:6 eval_loss = 198.23894260890782,train_loss = 9.619874024682213\n",
      "epoch:7 eval_loss = 197.5673576692492,train_loss = 6.050757286819862\n",
      "epoch:8 eval_loss = 197.11165327522903,train_loss = 3.829193403525278\n",
      "epoch:9 eval_loss = 196.7768082438223,train_loss = 2.4436982403043657\n",
      "epoch:10 eval_loss = 196.55395402989816,train_loss = 1.5647295889768429\n",
      "epoch:11 eval_loss = 196.4039196276781,train_loss = 1.0098844512889626\n",
      "epoch:12 eval_loss = 196.29459929717305,train_loss = 0.6554936545901\n",
      "epoch:13 eval_loss = 196.2241386250849,train_loss = 0.4273347499314696\n",
      "epoch:14 eval_loss = 196.17109976935433,train_loss = 0.27961055041232613\n",
      "epoch:15 eval_loss = 196.13589922701473,train_loss = 0.18417626227019354\n",
      "epoch:16 eval_loss = 196.1131326146517,train_loss = 0.12169122281484306\n",
      "epoch:17 eval_loss = 196.10130375048146,train_loss = 0.08066244569199625\n",
      "epoch:18 eval_loss = 196.09386001512874,train_loss = 0.05369766199410151\n",
      "epoch:19 eval_loss = 196.0898557790939,train_loss = 0.035906153809901295\n",
      "epoch:20 eval_loss = 196.08718355138467,train_loss = 0.02410312582019287\n",
      "epoch:21 eval_loss = 196.08694790362745,train_loss = 0.016242950488378937\n",
      "epoch:22 eval_loss = 196.08739722675753,train_loss = 0.010977321359976599\n",
      "epoch:23 eval_loss = 196.08899919460939,train_loss = 0.007448692980142368\n",
      "epoch:24 eval_loss = 196.09092939286919,train_loss = 0.005071124707137642\n",
      "epoch:25 eval_loss = 196.09300971188625,train_loss = 0.003469269708148204\n",
      "epoch:26 eval_loss = 196.09454819448365,train_loss = 0.0023785358190252736\n",
      "epoch:27 eval_loss = 196.09633902695933,train_loss = 0.0016382510998752763\n",
      "epoch:28 eval_loss = 196.09770931390375,train_loss = 0.0011339166864217987\n",
      "epoch:29 eval_loss = 196.09923800265418,train_loss = 0.0007869646474773617\n",
      "epoch:30 eval_loss = 196.1003663378497,train_loss = 0.000548254079990329\n",
      "epoch:31 eval_loss = 196.10169944788038,train_loss = 0.00038376854113266747\n",
      "epoch:32 eval_loss = 196.10273716430936,train_loss = 0.00026897848222905976\n",
      "epoch:33 eval_loss = 196.10348485635362,train_loss = 0.0001894782618379054\n",
      "epoch:34 eval_loss = 196.10423328274976,train_loss = 0.00013377266610608006\n",
      "epoch:35 eval_loss = 196.10466324747946,train_loss = 9.488267229595948e-05\n",
      "epoch:36 eval_loss = 196.10526094441883,train_loss = 6.74060957156275e-05\n",
      "epoch:37 eval_loss = 196.10565551531442,train_loss = 4.8067949786911865e-05\n",
      "epoch:38 eval_loss = 196.10607119315188,train_loss = 3.431868677741257e-05\n",
      "epoch:39 eval_loss = 196.10631084105873,train_loss = 2.4620738087577366e-05\n",
      "epoch:40 eval_loss = 196.10658823488396,train_loss = 1.7695941543571793e-05\n",
      "epoch:41 eval_loss = 196.10670062845864,train_loss = 1.2751655368248294e-05\n",
      "epoch:42 eval_loss = 196.10691325177555,train_loss = 9.191756330650946e-06\n",
      "epoch:43 eval_loss = 196.10702092035208,train_loss = 6.660265930236164e-06\n",
      "epoch:44 eval_loss = 196.1071584244311,train_loss = 4.8355544606693e-06\n",
      "epoch:45 eval_loss = 196.10723013348937,train_loss = 3.512692932616801e-06\n",
      "epoch:46 eval_loss = 196.10733150064246,train_loss = 2.5587577759722534e-06\n",
      "epoch:47 eval_loss = 196.10741052999276,train_loss = 1.8635042000170188e-06\n",
      "epoch:48 eval_loss = 196.1074479331833,train_loss = 1.364087625987942e-06\n",
      "epoch:49 eval_loss = 196.10749827667314,train_loss = 9.981742886466804e-07\n",
      "epoch:50 eval_loss = 196.10753170316806,train_loss = 7.271496437422087e-07\n",
      "epoch:51 eval_loss = 196.10757277995756,train_loss = 5.356488150143334e-07\n",
      "epoch:52 eval_loss = 196.107593222789,train_loss = 3.9386192154378106e-07\n",
      "epoch:53 eval_loss = 196.10761671699757,train_loss = 2.891193665838232e-07\n",
      "epoch:54 eval_loss = 196.10763745695527,train_loss = 2.1436739437163955e-07\n",
      "epoch:55 eval_loss = 196.107648358781,train_loss = 1.573253431641497e-07\n",
      "epoch:56 eval_loss = 196.10766906516858,train_loss = 1.148747040664866e-07\n",
      "epoch:57 eval_loss = 196.10767571627161,train_loss = 8.451217346008843e-08\n",
      "epoch:58 eval_loss = 196.10765924391046,train_loss = 6.256018991734891e-08\n",
      "epoch:59 eval_loss = 196.10764118179213,train_loss = 4.609710692951574e-08\n",
      "epoch:60 eval_loss = 196.10768320680015,train_loss = 3.4342464316772237e-08\n",
      "epoch:61 eval_loss = 196.10768151937984,train_loss = 2.565977778312689e-08\n",
      "epoch:62 eval_loss = 196.10767379890953,train_loss = 1.8832946732660894e-08\n",
      "epoch:63 eval_loss = 196.10767465288984,train_loss = 1.3635088801089434e-08\n",
      "epoch:64 eval_loss = 196.10769471340814,train_loss = 1.0317724112585136e-08\n",
      "epoch:65 eval_loss = 196.1076875454164,train_loss = 7.851349931309315e-09\n",
      "epoch:66 eval_loss = 196.10767207015888,train_loss = 5.734225007325566e-09\n",
      "epoch:67 eval_loss = 196.10766977900872,train_loss = 4.263333910209388e-09\n",
      "epoch:68 eval_loss = 196.10767447440188,train_loss = 3.1522170658437877e-09\n",
      "epoch:69 eval_loss = 196.10766009749844,train_loss = 2.4676651007304874e-09\n",
      "epoch:70 eval_loss = 196.1076626985427,train_loss = 1.8014148527034647e-09\n",
      "epoch:71 eval_loss = 196.10765097401512,train_loss = 1.3966551054567233e-09\n",
      "epoch:72 eval_loss = 196.1076709733723,train_loss = 1.0123828407537783e-09\n",
      "epoch:73 eval_loss = 196.10766888522076,train_loss = 7.842641897015668e-10\n",
      "epoch:74 eval_loss = 196.10767177854024,train_loss = 5.870998640369885e-10\n",
      "epoch:75 eval_loss = 196.10767558913736,train_loss = 4.2525829177519905e-10\n",
      "epoch:76 eval_loss = 196.1077126453165,train_loss = 3.706501725334044e-10\n",
      "epoch:77 eval_loss = 196.10770149851916,train_loss = 2.763692894328096e-10\n",
      "epoch:78 eval_loss = 196.10769163612218,train_loss = 2.321803985183557e-10\n",
      "epoch:79 eval_loss = 196.1076922698476,train_loss = 1.812318288496595e-10\n",
      "epoch:80 eval_loss = 196.1076965264231,train_loss = 1.6926793230953584e-10\n",
      "epoch:81 eval_loss = 196.10770092696532,train_loss = 1.4124668448745048e-10\n",
      "epoch:82 eval_loss = 196.10769855775055,train_loss = 1.2215598064330146e-10\n",
      "epoch:83 eval_loss = 196.1077044163458,train_loss = 1.0220279709344248e-10\n",
      "epoch:84 eval_loss = 196.10770903366443,train_loss = 9.45873540950104e-11\n",
      "epoch:85 eval_loss = 196.10770974980494,train_loss = 8.414410921503412e-11\n",
      "epoch:86 eval_loss = 196.10771067477413,train_loss = 6.93403192503217e-11\n",
      "epoch:87 eval_loss = 196.10770344913354,train_loss = 6.407614820680419e-11\n",
      "epoch:88 eval_loss = 196.10770043219264,train_loss = 5.3734211177824954e-11\n",
      "epoch:89 eval_loss = 196.10770666857425,train_loss = 5.065329492653925e-11\n",
      "epoch:90 eval_loss = 196.10771611784642,train_loss = 4.894923997383893e-11\n",
      "epoch:91 eval_loss = 196.1077118205966,train_loss = 4.7429280815303174e-11\n",
      "epoch:92 eval_loss = 196.10771474430862,train_loss = 4.188751949463221e-11\n",
      "epoch:93 eval_loss = 196.1077112621779,train_loss = 4.029765236779337e-11\n",
      "epoch:94 eval_loss = 196.1077158931538,train_loss = 3.928857343626913e-11\n",
      "epoch:95 eval_loss = 196.10771256446722,train_loss = 4.1627448363334983e-11\n",
      "epoch:96 eval_loss = 196.10771768266218,train_loss = 3.926543777621472e-11\n",
      "epoch:97 eval_loss = 196.10772315281326,train_loss = 3.544358521956337e-11\n",
      "epoch:98 eval_loss = 196.1077204462589,train_loss = 3.396638907637861e-11\n",
      "epoch:99 eval_loss = 196.1077208459098,train_loss = 3.1909255446271875e-11\n",
      "epoch:100 eval_loss = 196.10772289438523,train_loss = 2.9997726178065954e-11\n",
      "epoch:101 eval_loss = 196.10772274653078,train_loss = 3.137591818302976e-11\n",
      "epoch:102 eval_loss = 196.1077268858033,train_loss = 2.7215476747222132e-11\n",
      "epoch:103 eval_loss = 196.10772610124258,train_loss = 2.503487660232562e-11\n",
      "epoch:104 eval_loss = 196.1077254782262,train_loss = 2.4936165285427413e-11\n",
      "epoch:105 eval_loss = 196.10772282542487,train_loss = 2.5354765162410864e-11\n",
      "epoch:106 eval_loss = 196.10772659887385,train_loss = 2.2053331036331337e-11\n",
      "epoch:107 eval_loss = 196.10772003950436,train_loss = 2.206007286564837e-11\n",
      "epoch:108 eval_loss = 196.10772189666343,train_loss = 2.0422847787915365e-11\n",
      "epoch:109 eval_loss = 196.10771873642517,train_loss = 2.0154384758330758e-11\n",
      "epoch:110 eval_loss = 196.10771861217682,train_loss = 1.9257813052564466e-11\n",
      "epoch:111 eval_loss = 196.10772018671386,train_loss = 1.8439006918558044e-11\n",
      "epoch:112 eval_loss = 196.10772369210375,train_loss = 1.744685472482299e-11\n",
      "epoch:113 eval_loss = 196.10772571295675,train_loss = 1.8299808543509322e-11\n",
      "epoch:114 eval_loss = 196.1077233403665,train_loss = 1.527892500019501e-11\n",
      "epoch:115 eval_loss = 196.1077269317617,train_loss = 1.466655512316617e-11\n",
      "epoch:116 eval_loss = 196.10772753017548,train_loss = 1.622676541745971e-11\n",
      "epoch:117 eval_loss = 196.1077286436275,train_loss = 1.4990637550726936e-11\n",
      "epoch:118 eval_loss = 196.10772601243633,train_loss = 1.4205597462235709e-11\n",
      "epoch:119 eval_loss = 196.10772756428108,train_loss = 1.4410942925091597e-11\n",
      "epoch:120 eval_loss = 196.1077287136426,train_loss = 1.3454430278225793e-11\n",
      "epoch:121 eval_loss = 196.10772277031094,train_loss = 1.2478752406397398e-11\n",
      "epoch:122 eval_loss = 196.10772478208878,train_loss = 1.4472318829450436e-11\n",
      "epoch:123 eval_loss = 196.10772354918765,train_loss = 1.3906299375920916e-11\n",
      "epoch:124 eval_loss = 196.1077223965671,train_loss = 1.2505049426514426e-11\n",
      "epoch:125 eval_loss = 196.10772410539212,train_loss = 1.4061705619350385e-11\n",
      "epoch:126 eval_loss = 196.1077251762111,train_loss = 1.2371080201911689e-11\n",
      "epoch:127 eval_loss = 196.1077250641375,train_loss = 1.206768816819359e-11\n",
      "epoch:128 eval_loss = 196.10772446839894,train_loss = 1.1786841988548069e-11\n",
      "epoch:129 eval_loss = 196.10772217287567,train_loss = 1.1954679954295777e-11\n",
      "epoch:130 eval_loss = 196.1077217340615,train_loss = 1.0095697541845362e-11\n",
      "epoch:131 eval_loss = 196.1077210720681,train_loss = 1.0146907966634977e-11\n",
      "epoch:132 eval_loss = 196.10772024296747,train_loss = 1.1380304684727172e-11\n",
      "epoch:133 eval_loss = 196.10772007184627,train_loss = 1.0631162269958416e-11\n",
      "epoch:134 eval_loss = 196.10771969828522,train_loss = 1.0408655534699385e-11\n",
      "epoch:135 eval_loss = 196.10772193081502,train_loss = 9.421341137794138e-12\n",
      "epoch:136 eval_loss = 196.10772346701472,train_loss = 9.952427423853827e-12\n",
      "epoch:137 eval_loss = 196.1077215906605,train_loss = 9.981087831234526e-12\n",
      "epoch:138 eval_loss = 196.1077209398453,train_loss = 1.0186330598460635e-11\n",
      "epoch:139 eval_loss = 196.10771983696554,train_loss = 9.654182661633649e-12\n",
      "epoch:140 eval_loss = 196.10771910267357,train_loss = 1.0250673573852787e-11\n",
      "epoch:141 eval_loss = 196.1077181765664,train_loss = 9.710566725718017e-12\n",
      "epoch:142 eval_loss = 196.10771741835808,train_loss = 9.802210085285701e-12\n",
      "epoch:143 eval_loss = 196.10771717995638,train_loss = 1.1112437012239517e-11\n",
      "epoch:144 eval_loss = 196.10771666497226,train_loss = 1.2337069907331077e-11\n",
      "epoch:145 eval_loss = 196.10771588137607,train_loss = 1.1116023032609057e-11\n",
      "epoch:146 eval_loss = 196.10771404211468,train_loss = 1.2339202923317139e-11\n",
      "epoch:147 eval_loss = 196.10771485556907,train_loss = 1.0832753791212291e-11\n",
      "epoch:148 eval_loss = 196.10771375402285,train_loss = 1.0173637973731608e-11\n",
      "epoch:149 eval_loss = 196.10771015171542,train_loss = 1.1641338934498258e-11\n",
      "epoch:150 eval_loss = 196.1077108550613,train_loss = 1.1318225176526475e-11\n",
      "epoch:151 eval_loss = 196.10771487422986,train_loss = 9.281713939102154e-12\n",
      "epoch:152 eval_loss = 196.1077158638189,train_loss = 8.811402649189226e-12\n",
      "epoch:153 eval_loss = 196.10771571290738,train_loss = 9.112966978253034e-12\n",
      "epoch:154 eval_loss = 196.10771417725132,train_loss = 9.014245946903365e-12\n",
      "epoch:155 eval_loss = 196.10771549257683,train_loss = 9.203201742358224e-12\n",
      "epoch:156 eval_loss = 196.10771967113251,train_loss = 1.0168762706874723e-11\n",
      "epoch:157 eval_loss = 196.10771867695496,train_loss = 9.758306315776898e-12\n",
      "epoch:158 eval_loss = 196.10772036838577,train_loss = 9.93099595614222e-12\n",
      "epoch:159 eval_loss = 196.1077211302519,train_loss = 7.042870106555022e-12\n",
      "epoch:160 eval_loss = 196.10772099198016,train_loss = 7.335308402356411e-12\n",
      "epoch:161 eval_loss = 196.10772245947447,train_loss = 7.328513837445704e-12\n",
      "epoch:162 eval_loss = 196.10772419158545,train_loss = 7.364979112689519e-12\n",
      "epoch:163 eval_loss = 196.1077239133534,train_loss = 7.684179334499497e-12\n",
      "epoch:164 eval_loss = 196.10772310024535,train_loss = 7.268792165393556e-12\n",
      "epoch:165 eval_loss = 196.1077202489192,train_loss = 7.533807952486703e-12\n",
      "epoch:166 eval_loss = 196.10771927230584,train_loss = 8.302296003459552e-12\n",
      "epoch:167 eval_loss = 196.10771746893997,train_loss = 8.483226274225153e-12\n",
      "epoch:168 eval_loss = 196.1077175194549,train_loss = 8.392867997808473e-12\n",
      "epoch:169 eval_loss = 196.10771496286267,train_loss = 8.725353425886872e-12\n",
      "epoch:170 eval_loss = 196.10771801463153,train_loss = 8.83719590560883e-12\n",
      "epoch:171 eval_loss = 196.10771730742476,train_loss = 9.196135172806486e-12\n",
      "epoch:172 eval_loss = 196.1077168115141,train_loss = 8.355367439594197e-12\n",
      "epoch:173 eval_loss = 196.1077160274709,train_loss = 7.787531383640634e-12\n",
      "epoch:174 eval_loss = 196.10771658310725,train_loss = 7.871745963394793e-12\n",
      "epoch:175 eval_loss = 196.10771673423295,train_loss = 7.62401634879506e-12\n",
      "epoch:176 eval_loss = 196.1077214513073,train_loss = 8.491759725948178e-12\n",
      "epoch:177 eval_loss = 196.1077225843142,train_loss = 8.896145972658864e-12\n",
      "epoch:178 eval_loss = 196.10772343544056,train_loss = 8.974655393845232e-12\n",
      "epoch:179 eval_loss = 196.10772051469655,train_loss = 9.670618125734442e-12\n",
      "epoch:180 eval_loss = 196.10772051720298,train_loss = 9.614625415266254e-12\n",
      "epoch:181 eval_loss = 196.10771846173563,train_loss = 8.45121993220399e-12\n",
      "epoch:182 eval_loss = 196.1077182841877,train_loss = 8.714387197961138e-12\n",
      "epoch:183 eval_loss = 196.10771973182446,train_loss = 9.467225267623114e-12\n",
      "epoch:184 eval_loss = 196.10771792130953,train_loss = 9.747666215864648e-12\n",
      "epoch:185 eval_loss = 196.10771538618428,train_loss = 9.682125587384683e-12\n",
      "epoch:186 eval_loss = 196.10771590053454,train_loss = 9.051255231429246e-12\n",
      "epoch:187 eval_loss = 196.1077176493348,train_loss = 8.823259831092223e-12\n",
      "epoch:188 eval_loss = 196.1077169939672,train_loss = 7.849018310301936e-12\n",
      "epoch:189 eval_loss = 196.1077160355245,train_loss = 7.646165298136332e-12\n",
      "epoch:190 eval_loss = 196.1077160485834,train_loss = 7.322923864516717e-12\n",
      "epoch:191 eval_loss = 196.10771323497292,train_loss = 6.9222041293448555e-12\n",
      "epoch:192 eval_loss = 196.1077108461398,train_loss = 6.628602874925171e-12\n",
      "epoch:193 eval_loss = 196.10770943708602,train_loss = 6.725250564776353e-12\n",
      "epoch:194 eval_loss = 196.10770903126337,train_loss = 6.953118289465543e-12\n",
      "epoch:195 eval_loss = 196.10770882398822,train_loss = 6.584563103095853e-12\n",
      "epoch:196 eval_loss = 196.1077101372648,train_loss = 6.614104750002347e-12\n",
      "epoch:197 eval_loss = 196.10771057059057,train_loss = 5.94297493161644e-12\n",
      "epoch:198 eval_loss = 196.10771069993265,train_loss = 5.3646653092043195e-12\n",
      "epoch:199 eval_loss = 196.1077095180843,train_loss = 5.21641306538978e-12\n"
     ]
    }
   ],
   "source": [
    "train(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 eval_loss = 147.09832449089737,train_loss = 328.35225677490234\n",
      "epoch:1 eval_loss = 137.12287073327852,train_loss = 238.98553695678712\n",
      "epoch:2 eval_loss = 129.2263666125573,train_loss = 189.62548828125\n",
      "epoch:3 eval_loss = 122.4534746141918,train_loss = 160.8409622192383\n",
      "epoch:4 eval_loss = 116.3970226067886,train_loss = 142.8178565979004\n",
      "epoch:5 eval_loss = 110.8314888902381,train_loss = 130.44805145263672\n",
      "epoch:6 eval_loss = 105.60465847454965,train_loss = 121.17971839904786\n",
      "epoch:7 eval_loss = 100.65176296964229,train_loss = 113.73150634765625\n",
      "epoch:8 eval_loss = 95.9527870351635,train_loss = 107.3895320892334\n",
      "epoch:9 eval_loss = 91.47328376237303,train_loss = 101.76302070617676\n",
      "epoch:10 eval_loss = 87.20976167194546,train_loss = 96.6377140045166\n",
      "epoch:11 eval_loss = 83.14427143327892,train_loss = 91.89125556945801\n",
      "epoch:12 eval_loss = 79.261882258486,train_loss = 87.44974212646484\n",
      "epoch:13 eval_loss = 75.56377267713658,train_loss = 83.26573486328125\n",
      "epoch:14 eval_loss = 72.03174507295248,train_loss = 79.30780181884765\n",
      "epoch:15 eval_loss = 68.66462992421934,train_loss = 75.55487403869628\n",
      "epoch:16 eval_loss = 65.45214919729304,train_loss = 71.98949813842773\n",
      "epoch:17 eval_loss = 62.38925354095427,train_loss = 68.59921073913574\n",
      "epoch:18 eval_loss = 59.467154401322475,train_loss = 65.37278747558594\n",
      "epoch:19 eval_loss = 56.68246027906367,train_loss = 62.300954055786136\n",
      "epoch:20 eval_loss = 54.02791266739485,train_loss = 59.37530155181885\n",
      "epoch:21 eval_loss = 51.49660615746514,train_loss = 56.58827228546143\n",
      "epoch:22 eval_loss = 49.0830866325309,train_loss = 53.93298206329346\n",
      "epoch:23 eval_loss = 46.78333619573852,train_loss = 51.40291213989258\n",
      "epoch:24 eval_loss = 44.591042277516095,train_loss = 48.9918794631958\n",
      "epoch:25 eval_loss = 42.501089130102194,train_loss = 46.69423580169678\n",
      "epoch:26 eval_loss = 40.509209692843726,train_loss = 44.50456275939941\n",
      "epoch:27 eval_loss = 38.6108884797222,train_loss = 42.417717933654785\n",
      "epoch:28 eval_loss = 36.801310254217825,train_loss = 40.42882118225098\n",
      "epoch:29 eval_loss = 35.0767568269209,train_loss = 38.53328590393066\n",
      "epoch:30 eval_loss = 33.43317916326923,train_loss = 36.72667217254639\n",
      "epoch:31 eval_loss = 31.86683836073382,train_loss = 35.00480403900146\n",
      "epoch:32 eval_loss = 30.373788759596646,train_loss = 33.36370372772217\n",
      "epoch:33 eval_loss = 28.95085296358564,train_loss = 31.799584007263185\n",
      "epoch:34 eval_loss = 27.59457486541476,train_loss = 30.308813858032227\n",
      "epoch:35 eval_loss = 26.302106242121663,train_loss = 28.887968826293946\n",
      "epoch:36 eval_loss = 25.07047107218299,train_loss = 27.533754062652587\n",
      "epoch:37 eval_loss = 23.896531084548915,train_loss = 26.2430438041687\n",
      "epoch:38 eval_loss = 22.777443105077836,train_loss = 25.012858867645264\n",
      "epoch:39 eval_loss = 21.711303539908258,train_loss = 23.84035987854004\n",
      "epoch:40 eval_loss = 20.695065590830055,train_loss = 22.722847747802735\n",
      "epoch:41 eval_loss = 19.7268372984312,train_loss = 21.65774278640747\n",
      "epoch:42 eval_loss = 18.804044216305485,train_loss = 20.64257926940918\n",
      "epoch:43 eval_loss = 17.92445818571956,train_loss = 19.675025844573973\n",
      "epoch:44 eval_loss = 17.08643097542692,train_loss = 18.752833461761476\n",
      "epoch:45 eval_loss = 16.287676395829767,train_loss = 17.873891162872315\n",
      "epoch:46 eval_loss = 15.526542728338391,train_loss = 17.0361536026001\n",
      "epoch:47 eval_loss = 14.800991823005024,train_loss = 16.237719297409058\n",
      "epoch:48 eval_loss = 14.109888608544134,train_loss = 15.47671718597412\n",
      "epoch:49 eval_loss = 13.45110761875636,train_loss = 14.751397132873535\n",
      "epoch:50 eval_loss = 12.823428654227174,train_loss = 14.060084056854247\n",
      "epoch:51 eval_loss = 12.224989719904261,train_loss = 13.40119833946228\n",
      "epoch:52 eval_loss = 11.654886116153794,train_loss = 12.773201656341552\n",
      "epoch:53 eval_loss = 11.111794058332453,train_loss = 12.174652004241944\n",
      "epoch:54 eval_loss = 10.594068663006183,train_loss = 11.604171705245971\n",
      "epoch:55 eval_loss = 10.100727573847399,train_loss = 11.060451459884643\n",
      "epoch:56 eval_loss = 9.630388573786476,train_loss = 10.542210245132447\n",
      "epoch:57 eval_loss = 9.182458496022736,train_loss = 10.048277378082275\n",
      "epoch:58 eval_loss = 8.755534353150288,train_loss = 9.577514171600342\n",
      "epoch:59 eval_loss = 8.348557978026802,train_loss = 9.128808212280273\n",
      "epoch:60 eval_loss = 7.960848906215396,train_loss = 8.701161575317382\n",
      "epoch:61 eval_loss = 7.591303394868155,train_loss = 8.293550777435303\n",
      "epoch:62 eval_loss = 7.239180969053995,train_loss = 7.905057382583618\n",
      "epoch:63 eval_loss = 6.9035511532449165,train_loss = 7.534793901443481\n",
      "epoch:64 eval_loss = 6.583839841816808,train_loss = 7.181873679161072\n",
      "epoch:65 eval_loss = 6.279162134632934,train_loss = 6.8455044507980345\n",
      "epoch:66 eval_loss = 5.988776884232066,train_loss = 6.524924111366272\n",
      "epoch:67 eval_loss = 5.7120841001186635,train_loss = 6.2193646907806395\n",
      "epoch:68 eval_loss = 5.448357430280448,train_loss = 5.928127646446228\n",
      "epoch:69 eval_loss = 5.197080395593948,train_loss = 5.650551080703735\n",
      "epoch:70 eval_loss = 4.957675610164297,train_loss = 5.385989475250244\n",
      "epoch:71 eval_loss = 4.729486961490402,train_loss = 5.133833432197571\n",
      "epoch:72 eval_loss = 4.512144729918509,train_loss = 4.893501234054566\n",
      "epoch:73 eval_loss = 4.30486133969092,train_loss = 4.664439463615418\n",
      "epoch:74 eval_loss = 4.107513754806587,train_loss = 4.446117281913757\n",
      "epoch:75 eval_loss = 3.919347256765468,train_loss = 4.238023638725281\n",
      "epoch:76 eval_loss = 3.740184829453865,train_loss = 4.039705193042755\n",
      "epoch:77 eval_loss = 3.569256576185344,train_loss = 3.8506721019744874\n",
      "epoch:78 eval_loss = 3.406416857178193,train_loss = 3.670494329929352\n",
      "epoch:79 eval_loss = 3.2512823591462436,train_loss = 3.4987865805625917\n",
      "epoch:80 eval_loss = 3.103476807871339,train_loss = 3.3351102232933045\n",
      "epoch:81 eval_loss = 2.9626141040359837,train_loss = 3.179124927520752\n",
      "epoch:82 eval_loss = 2.82841705243889,train_loss = 3.0304332852363585\n",
      "epoch:83 eval_loss = 2.7005489109025804,train_loss = 2.888726735115051\n",
      "epoch:84 eval_loss = 2.578575407166791,train_loss = 2.7536629915237425\n",
      "epoch:85 eval_loss = 2.4624678333874908,train_loss = 2.624932646751404\n",
      "epoch:86 eval_loss = 2.351738987316494,train_loss = 2.5022353768348693\n",
      "epoch:87 eval_loss = 2.2463104388769715,train_loss = 2.3852896690368652\n",
      "epoch:88 eval_loss = 2.145833576293808,train_loss = 2.273833763599396\n",
      "epoch:89 eval_loss = 2.0500333830401916,train_loss = 2.167594337463379\n",
      "epoch:90 eval_loss = 1.9587366612969346,train_loss = 2.0663366079330445\n",
      "epoch:91 eval_loss = 1.87189027770306,train_loss = 1.9698307394981385\n",
      "epoch:92 eval_loss = 1.7891201364609879,train_loss = 1.877844101190567\n",
      "epoch:93 eval_loss = 1.7101658941683127,train_loss = 1.7901679933071137\n",
      "epoch:94 eval_loss = 1.6348994813769968,train_loss = 1.706609272956848\n",
      "epoch:95 eval_loss = 1.5632169281232386,train_loss = 1.6269656658172607\n",
      "epoch:96 eval_loss = 1.4949335931098175,train_loss = 1.551058030128479\n",
      "epoch:97 eval_loss = 1.4298633363170665,train_loss = 1.4787066102027893\n",
      "epoch:98 eval_loss = 1.3678356411750427,train_loss = 1.4097479164600373\n",
      "epoch:99 eval_loss = 1.3086726608589379,train_loss = 1.3440156936645509\n",
      "epoch:100 eval_loss = 1.252338042788615,train_loss = 1.281376802921295\n",
      "epoch:101 eval_loss = 1.198680981159414,train_loss = 1.2216631889343261\n",
      "epoch:102 eval_loss = 1.1475868177582742,train_loss = 1.164755928516388\n",
      "epoch:103 eval_loss = 1.0988182192926614,train_loss = 1.1105034291744231\n",
      "epoch:104 eval_loss = 1.0524162259979584,train_loss = 1.0588129997253417\n",
      "epoch:105 eval_loss = 1.0081923249046667,train_loss = 1.009526687860489\n",
      "epoch:106 eval_loss = 0.9660203900477063,train_loss = 0.9625638663768769\n",
      "epoch:107 eval_loss = 0.9258353012080807,train_loss = 0.9177976816892623\n",
      "epoch:108 eval_loss = 0.8875474338279997,train_loss = 0.8751342117786407\n",
      "epoch:109 eval_loss = 0.8510657931041067,train_loss = 0.8344635754823685\n",
      "epoch:110 eval_loss = 0.8162345407632255,train_loss = 0.7957041144371033\n",
      "epoch:111 eval_loss = 0.7830960698098351,train_loss = 0.7587561726570129\n",
      "epoch:112 eval_loss = 0.7515418754794154,train_loss = 0.7235407054424285\n",
      "epoch:113 eval_loss = 0.7214608913879988,train_loss = 0.689975717663765\n",
      "epoch:114 eval_loss = 0.6928150426279536,train_loss = 0.657984372973442\n",
      "epoch:115 eval_loss = 0.6654987315101789,train_loss = 0.6274962961673737\n",
      "epoch:116 eval_loss = 0.6394590607079772,train_loss = 0.5984389930963516\n",
      "epoch:117 eval_loss = 0.6146535863809549,train_loss = 0.570735639333725\n",
      "epoch:118 eval_loss = 0.5909571775712311,train_loss = 0.544328898191452\n",
      "epoch:119 eval_loss = 0.568393648513238,train_loss = 0.5191587120294571\n",
      "epoch:120 eval_loss = 0.5469264963712931,train_loss = 0.4951831430196762\n",
      "epoch:121 eval_loss = 0.52644860225284,train_loss = 0.4723157823085785\n",
      "epoch:122 eval_loss = 0.5069268632880738,train_loss = 0.45052524358034135\n",
      "epoch:123 eval_loss = 0.488318115740026,train_loss = 0.4297491252422333\n",
      "epoch:124 eval_loss = 0.47056038768244635,train_loss = 0.4099485620856285\n",
      "epoch:125 eval_loss = 0.45367352913067466,train_loss = 0.3910853505134583\n",
      "epoch:126 eval_loss = 0.43757223861757666,train_loss = 0.37310238033533094\n",
      "epoch:127 eval_loss = 0.4222011652950459,train_loss = 0.3559505954384804\n",
      "epoch:128 eval_loss = 0.40756364938292333,train_loss = 0.33961002230644227\n",
      "epoch:129 eval_loss = 0.3936192925885825,train_loss = 0.3240359455347061\n",
      "epoch:130 eval_loss = 0.3803383233369337,train_loss = 0.309195850789547\n",
      "epoch:131 eval_loss = 0.3676462230300956,train_loss = 0.2950409144163132\n",
      "epoch:132 eval_loss = 0.3555859773640077,train_loss = 0.2815534383058548\n",
      "epoch:133 eval_loss = 0.3440399279750818,train_loss = 0.26869497150182725\n",
      "epoch:134 eval_loss = 0.33304729596926336,train_loss = 0.2564431592822075\n",
      "epoch:135 eval_loss = 0.32261811893426057,train_loss = 0.24475748017430304\n",
      "epoch:136 eval_loss = 0.3126397007434571,train_loss = 0.23361851125955582\n",
      "epoch:137 eval_loss = 0.3031021531870465,train_loss = 0.22300682291388513\n",
      "epoch:138 eval_loss = 0.29399764517923815,train_loss = 0.21289534121751785\n",
      "epoch:139 eval_loss = 0.28535452174111925,train_loss = 0.20324535965919494\n",
      "epoch:140 eval_loss = 0.2771109338064639,train_loss = 0.19406243413686752\n",
      "epoch:141 eval_loss = 0.2692304922043695,train_loss = 0.18529218509793283\n",
      "epoch:142 eval_loss = 0.26172812013479413,train_loss = 0.17694855034351348\n",
      "epoch:143 eval_loss = 0.2545599147287521,train_loss = 0.16898396387696266\n",
      "epoch:144 eval_loss = 0.24772848614330542,train_loss = 0.16139996871352197\n",
      "epoch:145 eval_loss = 0.2412147249487589,train_loss = 0.15415851026773453\n",
      "epoch:146 eval_loss = 0.23500240856541496,train_loss = 0.14726826697587966\n",
      "epoch:147 eval_loss = 0.22907803338457597,train_loss = 0.14069660007953644\n",
      "epoch:148 eval_loss = 0.22340596030131565,train_loss = 0.13442693650722504\n",
      "epoch:149 eval_loss = 0.21796154832791217,train_loss = 0.12845394313335418\n",
      "epoch:150 eval_loss = 0.2128406891044506,train_loss = 0.12276282981038093\n",
      "epoch:151 eval_loss = 0.20795311219405277,train_loss = 0.11733384020626544\n",
      "epoch:152 eval_loss = 0.2032680390974565,train_loss = 0.11215627789497376\n",
      "epoch:153 eval_loss = 0.19875250913686615,train_loss = 0.10722771435976028\n",
      "epoch:154 eval_loss = 0.19447797170453526,train_loss = 0.10252812430262566\n",
      "epoch:155 eval_loss = 0.19039202419160575,train_loss = 0.09804057888686657\n",
      "epoch:156 eval_loss = 0.1864971770003831,train_loss = 0.09377369172871113\n",
      "epoch:157 eval_loss = 0.18275315303773823,train_loss = 0.08970068208873272\n",
      "epoch:158 eval_loss = 0.17920906289595792,train_loss = 0.08581587076187133\n",
      "epoch:159 eval_loss = 0.1757985090895545,train_loss = 0.08211619742214679\n",
      "epoch:160 eval_loss = 0.17255497516968135,train_loss = 0.07858634479343891\n",
      "epoch:161 eval_loss = 0.16945172816430953,train_loss = 0.07522147260606289\n",
      "epoch:162 eval_loss = 0.16648104776924605,train_loss = 0.07201187238097191\n",
      "epoch:163 eval_loss = 0.16363174677942197,train_loss = 0.06895382665097713\n",
      "epoch:164 eval_loss = 0.16092917679883156,train_loss = 0.06603938266634941\n",
      "epoch:165 eval_loss = 0.15833376916216366,train_loss = 0.0632538441568613\n",
      "epoch:166 eval_loss = 0.15585871022733044,train_loss = 0.0606046361848712\n",
      "epoch:167 eval_loss = 0.15348357237754498,train_loss = 0.05807960946112871\n",
      "epoch:168 eval_loss = 0.15120204433114623,train_loss = 0.0556739766150713\n",
      "epoch:169 eval_loss = 0.1490115938929557,train_loss = 0.05337331891059875\n",
      "epoch:170 eval_loss = 0.14695434338258564,train_loss = 0.05118202827870846\n",
      "epoch:171 eval_loss = 0.14495592507848187,train_loss = 0.049097217805683616\n",
      "epoch:172 eval_loss = 0.14303944922427944,train_loss = 0.04710706491023302\n",
      "epoch:173 eval_loss = 0.14119730782041473,train_loss = 0.04520779885351658\n",
      "epoch:174 eval_loss = 0.1394410982869431,train_loss = 0.04339553192257881\n",
      "epoch:175 eval_loss = 0.13777873843569977,train_loss = 0.041668659821152684\n",
      "epoch:176 eval_loss = 0.13617429399229877,train_loss = 0.04002676531672478\n",
      "epoch:177 eval_loss = 0.13463305093399414,train_loss = 0.03845098149031401\n",
      "epoch:178 eval_loss = 0.13315784189233867,train_loss = 0.03695249613374472\n",
      "epoch:179 eval_loss = 0.1317304249158565,train_loss = 0.03553056605160236\n",
      "epoch:180 eval_loss = 0.13037266976137743,train_loss = 0.03416599966585636\n",
      "epoch:181 eval_loss = 0.12907034656741417,train_loss = 0.03287405651062727\n",
      "epoch:182 eval_loss = 0.12784735521303447,train_loss = 0.03162807933986187\n",
      "epoch:183 eval_loss = 0.1266469144824446,train_loss = 0.03045047651976347\n",
      "epoch:184 eval_loss = 0.1254676743314485,train_loss = 0.029320211708545686\n",
      "epoch:185 eval_loss = 0.1243525297823362,train_loss = 0.028253086283802985\n",
      "epoch:186 eval_loss = 0.12326131322915898,train_loss = 0.02722282651811838\n",
      "epoch:187 eval_loss = 0.12223546877123226,train_loss = 0.02624357184395194\n",
      "epoch:188 eval_loss = 0.12126944893951304,train_loss = 0.025314185582101346\n",
      "epoch:189 eval_loss = 0.12030751340593042,train_loss = 0.024424178153276445\n",
      "epoch:190 eval_loss = 0.11939032215626981,train_loss = 0.023575703985989092\n",
      "epoch:191 eval_loss = 0.11851246578619794,train_loss = 0.022772336658090354\n",
      "epoch:192 eval_loss = 0.1176353878107875,train_loss = 0.021990931034088133\n",
      "epoch:193 eval_loss = 0.11683907302480293,train_loss = 0.02125375811010599\n",
      "epoch:194 eval_loss = 0.11604017589238992,train_loss = 0.0205521734431386\n",
      "epoch:195 eval_loss = 0.11528103932898773,train_loss = 0.01988365864381194\n",
      "epoch:196 eval_loss = 0.11453816861227566,train_loss = 0.01924301153048873\n",
      "epoch:197 eval_loss = 0.11382156126059044,train_loss = 0.018637013249099256\n",
      "epoch:198 eval_loss = 0.1131167300201696,train_loss = 0.018051795847713947\n",
      "epoch:199 eval_loss = 0.11243745619365654,train_loss = 0.017487740702927114\n"
     ]
    }
   ],
   "source": [
    "train(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于权重衰减在神经网络优化中很常用， 深度学习框架为了便于我们使用权重衰减， 将权重衰减集成到优化算法中，以便与任何损失函数结合使用。 此外，这种集成还有计算上的好处， 允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。 由于更新的权重衰减部分仅依赖于每个参数的当前值， 因此优化器必须至少接触每个参数一次。\n",
    "\n",
    "```python\n",
    "def train_concise(wd):\n",
    "    net = nn.Sequential(nn.Linear(num_inputs, 1))\n",
    "    for param in net.parameters():\n",
    "        param.data.normal_()\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    num_epochs, lr = 100, 0.003\n",
    "    # 偏置参数没有衰减\n",
    "    trainer = torch.optim.SGD([\n",
    "        {\"params\":net[0].weight,'weight_decay': wd},\n",
    "        {\"params\":net[0].bias}], lr=lr)\n",
    "    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',\n",
    "                            xlim=[5, num_epochs], legend=['train', 'test'])\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.mean().backward()\n",
    "            trainer.step()\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            animator.add(epoch + 1,\n",
    "                         (d2l.evaluate_loss(net, train_iter, loss),\n",
    "                          d2l.evaluate_loss(net, test_iter, loss)))\n",
    "    print('w的L2范数：', net[0].weight.norm().item())\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d6d563c462dbcb2ee090b6970b42fc638e8eb4a4e6decc12c92a9df43cdf15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
