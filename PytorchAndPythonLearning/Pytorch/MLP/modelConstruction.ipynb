{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构建神经网络"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2184, -0.1246, -0.3069, -0.1231,  0.2214,  0.0748, -0.0781, -0.0495,\n",
       "         -0.0786,  0.1601],\n",
       "        [-0.1297, -0.0631, -0.1651, -0.1537,  0.1547,  0.0761, -0.1151,  0.0107,\n",
       "         -0.0533,  0.1484]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "net = nn.Sequential(\n",
    "    nn.Linear(20,256),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(256,10)\n",
    ")\n",
    "x= t.rand(2,20)\n",
    "net.__call__(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自定义块"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        self.hiddenlayer =nn.Linear(20,256)\n",
    "        self.out=nn.Linear(256,10)\n",
    "    \n",
    "    def forward(self,x:t.Tensor)->t.Tensor:\n",
    "        return self.out(F.relu(self.hiddenlayer(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 访问参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n",
      "OrderedDict([('0.weight', tensor([[-0.0326, -0.0051,  0.0228,  ...,  0.0373,  0.1676,  0.2226],\n",
      "        [-0.1780, -0.0970,  0.2203,  ..., -0.0500, -0.1720,  0.1716],\n",
      "        [-0.1741, -0.1578, -0.1534,  ..., -0.1381,  0.0184,  0.1033],\n",
      "        ...,\n",
      "        [ 0.1253,  0.0190, -0.1344,  ...,  0.0071, -0.0855,  0.0377],\n",
      "        [ 0.0015,  0.1829,  0.1553,  ..., -0.0214,  0.0093, -0.0173],\n",
      "        [-0.0141,  0.0748, -0.0406,  ...,  0.0551, -0.0188,  0.0810]])), ('0.bias', tensor([-6.1359e-03,  2.0157e-01,  2.0241e-01, -1.8358e-01,  1.6756e-01,\n",
      "         9.5332e-02, -8.5847e-02,  1.0530e-01, -1.9624e-01,  1.6841e-01,\n",
      "         1.6243e-01, -9.2269e-02, -2.6228e-02, -7.6428e-02, -1.0929e-01,\n",
      "         1.2159e-01, -1.2244e-01, -1.7100e-01,  3.4832e-02, -6.6359e-02,\n",
      "        -6.4313e-02, -1.5158e-02,  3.1494e-02,  1.9315e-02, -1.3078e-01,\n",
      "        -1.9644e-01, -8.8333e-02, -2.1129e-01,  1.5467e-01,  1.5130e-02,\n",
      "        -1.6719e-01,  1.6367e-02,  5.8001e-02,  1.5354e-01,  1.6089e-01,\n",
      "        -4.5829e-02,  1.4275e-01, -4.8545e-03,  1.5302e-01, -1.9293e-01,\n",
      "        -1.6980e-01, -2.1142e-01, -1.7436e-01, -1.1295e-01, -1.8408e-01,\n",
      "         1.6794e-01, -1.5852e-01,  1.8593e-01, -2.0893e-01, -2.0900e-01,\n",
      "         1.0227e-01, -3.5975e-03, -1.9831e-01,  5.2094e-02, -5.0501e-02,\n",
      "        -1.7072e-01, -1.6534e-01, -1.7451e-01,  1.0545e-01,  7.3859e-02,\n",
      "        -3.2602e-02, -8.4670e-02, -1.0620e-03, -1.2235e-01,  2.1661e-01,\n",
      "        -7.6166e-02, -2.0638e-02, -1.4620e-02, -2.1436e-01,  5.9574e-02,\n",
      "         2.0544e-01, -2.8074e-02,  1.3725e-01, -1.0168e-01, -2.1418e-01,\n",
      "         1.9462e-01,  1.0772e-02, -2.2127e-01, -1.1388e-01, -1.1615e-02,\n",
      "        -5.3865e-02,  4.2619e-02,  1.9547e-01, -3.9890e-02,  1.0950e-01,\n",
      "         4.2170e-02,  1.8335e-01,  6.2972e-03, -1.0407e-01,  1.0095e-01,\n",
      "         1.2735e-01, -1.5334e-02, -1.3740e-01,  1.3246e-01,  1.4177e-01,\n",
      "        -1.0966e-01,  8.0301e-02, -1.0569e-04, -1.1289e-01,  4.8407e-03,\n",
      "         1.7477e-01, -2.6347e-03,  1.5829e-01, -8.5924e-02,  7.4802e-02,\n",
      "        -1.9063e-01, -9.7288e-02, -9.0779e-04,  1.1295e-01,  1.6351e-01,\n",
      "         1.1056e-01,  1.4162e-01, -7.9500e-02,  2.1200e-01,  1.2045e-01,\n",
      "         2.0010e-01,  7.8929e-02,  1.1630e-02, -1.6757e-01,  1.4865e-02,\n",
      "        -9.0394e-02, -1.2323e-01, -1.3335e-01, -9.1411e-02,  1.4665e-01,\n",
      "        -2.1124e-01,  1.7760e-01,  2.1544e-02,  4.9906e-03,  1.6564e-02,\n",
      "        -1.5871e-01, -1.4353e-01, -3.1750e-02, -8.2592e-02,  1.4621e-01,\n",
      "        -1.2784e-01,  1.1359e-01,  1.1483e-03,  1.4796e-01, -6.1728e-02,\n",
      "        -7.1107e-02, -1.8843e-01,  9.6106e-02, -3.9639e-02,  1.0763e-01,\n",
      "         1.2741e-01, -1.8944e-01,  1.2452e-01,  2.0716e-01,  1.6166e-01,\n",
      "        -1.3985e-01,  2.1031e-01, -3.4295e-02,  6.0056e-02,  2.1126e-01,\n",
      "         1.4947e-01,  6.7498e-02,  6.1689e-02,  2.2334e-01,  5.7088e-02,\n",
      "         1.2692e-01, -1.1100e-01,  1.0394e-01,  1.2285e-01, -1.6810e-01,\n",
      "         1.9602e-01, -2.1763e-01,  1.6048e-01, -1.3531e-01,  1.9813e-01,\n",
      "         5.1284e-02,  3.3060e-02, -1.9678e-01, -8.4721e-03, -7.9208e-02,\n",
      "         1.9367e-01,  5.8609e-02, -1.0614e-01, -1.0411e-01,  5.7989e-02,\n",
      "         4.8148e-02,  1.7686e-01, -7.4332e-02, -2.1564e-02,  1.9373e-01,\n",
      "         2.0459e-01,  4.5479e-02, -1.0984e-01,  1.3098e-01, -2.0015e-01,\n",
      "         1.2885e-01, -5.0770e-02, -1.1802e-01,  2.5405e-02,  1.2583e-01,\n",
      "         9.0004e-02, -1.7232e-01,  3.4044e-02, -3.4027e-02, -8.3090e-02,\n",
      "         3.7585e-02, -1.6256e-01,  1.1773e-01, -1.0665e-01,  1.2219e-01,\n",
      "         1.6419e-01, -1.8336e-01, -1.5074e-03,  1.7761e-01,  1.0527e-01,\n",
      "        -1.5756e-01,  1.9888e-01, -1.1179e-01, -1.5366e-01, -3.2618e-02,\n",
      "        -1.6668e-01, -4.5142e-02,  1.4642e-01, -1.7518e-01,  1.5658e-01,\n",
      "        -1.6409e-01, -2.1799e-01, -5.6035e-02,  1.8245e-01, -7.6646e-02,\n",
      "         1.4109e-01, -4.9574e-02, -5.3129e-02, -9.5499e-02,  2.2091e-02,\n",
      "         1.7742e-01, -1.3470e-01,  2.9664e-02, -3.4224e-02,  1.4958e-01,\n",
      "         2.0525e-01,  1.6176e-01, -2.1297e-01,  1.4600e-01, -9.8655e-02,\n",
      "         4.6704e-03, -1.2179e-01, -2.0298e-01, -1.0686e-02,  2.2391e-02,\n",
      "         1.4926e-02,  1.7753e-01,  1.0805e-01, -2.8785e-02,  2.1489e-01,\n",
      "         1.0868e-01, -1.5235e-01,  3.3690e-02,  1.5678e-01,  8.5053e-03,\n",
      "         1.3305e-02])), ('2.weight', tensor([[ 0.0605, -0.0312, -0.0374,  ..., -0.0285,  0.0407, -0.0581],\n",
      "        [-0.0595, -0.0179, -0.0347,  ..., -0.0362,  0.0219, -0.0511],\n",
      "        [ 0.0580,  0.0612, -0.0548,  ..., -0.0422,  0.0277, -0.0471],\n",
      "        ...,\n",
      "        [-0.0468,  0.0304,  0.0150,  ..., -0.0239,  0.0150, -0.0392],\n",
      "        [-0.0203, -0.0550, -0.0375,  ...,  0.0467,  0.0605,  0.0134],\n",
      "        [ 0.0370, -0.0003,  0.0281,  ...,  0.0315,  0.0055, -0.0290]])), ('2.bias', tensor([-0.0569,  0.0562,  0.0259, -0.0391, -0.0069,  0.0184, -0.0029,  0.0025,\n",
      "         0.0029,  0.0517]))])\n",
      "<class 'torch.nn.parameter.Parameter'>\n"
     ]
    }
   ],
   "source": [
    "print(net)\n",
    "print(net.state_dict())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.nn.parameter.Parameter'>\n",
      "('weight', torch.Size([256, 20])) ('bias', torch.Size([256]))\n",
      "('0.weight', torch.Size([256, 20])) ('0.bias', torch.Size([256])) ('2.weight', torch.Size([10, 256])) ('2.bias', torch.Size([10]))\n"
     ]
    }
   ],
   "source": [
    "print(type(net[0].bias))\n",
    "#print(net[0].bias)\n",
    "#print(net[0].bias.data)\n",
    "print(*[(name, param.shape) for name, param in net[0].named_parameters()])\n",
    "print(*[(name, param.shape) for name, param in net.named_parameters()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0569,  0.0562,  0.0259, -0.0391, -0.0069,  0.0184, -0.0029,  0.0025,\n",
       "         0.0029,  0.0517])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.state_dict()['2.bias'].data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weight init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_normal(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.normal_(m.weight, mean=0, std=0.01)\n",
    "        nn.init.zeros_(m.bias)\n",
    "net.apply(init_normal)\n",
    "\n",
    "\n",
    "def xavier(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.xavier_uniform_(m.weight)\n",
    "\n",
    "\n",
    "def init_42(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        nn.init.constant_(m.weight, 42)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d6d563c462dbcb2ee090b6970b42fc638e8eb4a4e6decc12c92a9df43cdf15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
