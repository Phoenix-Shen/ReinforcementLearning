{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 权重衰减\n",
    "过拟合可以通过收集更多的训练数据来缓解过拟合，但是获取更多的数据会导致成本很高。\n",
    "\n",
    "如果有了很多高质量的数据，那么我们可以将重点放在正则化技术上。\n",
    "\n",
    "在[多项式回归](./overfittingAndUnderfitting.ipynb)中，我们通过限制特征的数量来缓解过拟合。但是这种简单地丢弃特征的行为太过于生硬。\n",
    "\n",
    "在训练参数化机器学习模型的时候，权重衰减（weight decay）是广泛使用的正则化技术之一，通常被称为L2正则化，通过函数与0的距离来衡量函数的复杂度。\n",
    "\n",
    "一种简单的方法是通过线性函数中权重向量的某个范数来度量复杂性，要保证权重向量比较小， 最常用方法是将其范数作为惩罚项加到最小化损失的问题中。 将原来的训练目标最小化训练标签上的预测损失， 调整为最小化预测损失和惩罚项之和。\n",
    "\n",
    "**为什么可以防止过拟合呢？**\n",
    "1. 从模型的复杂度上解释：更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合更好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果。\n",
    "2. 从数学方面的解释：过拟合的时候，拟合函数的系数往往非常大，在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大。而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from pltutils import *\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 生成数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_w,true_b=t.ones((200))*0.01,0.05\n",
    "X= t.normal(0,1,size=(20+100,200))\n",
    "Y=t.zeros((120,1))\n",
    "for i in range(100+20):\n",
    "    Y[i]=true_b+(X[i]*true_w).sum()+t.normal(0,0.01,(1,))\n",
    "\n",
    "\n",
    "def data_iter(batch_size: int, features: t.Tensor, labels: t.Tensor):\n",
    "    num_examples = len(features)\n",
    "    indices = list(range(num_examples))\n",
    "    random.shuffle(indices)\n",
    "    for i in range(0, num_examples, batch_size):\n",
    "        batch_indices = t.tensor(\n",
    "            indices[i:min(i+batch_size, num_examples)])\n",
    "        yield features[batch_indices], labels[batch_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netwrok architecture\n",
    "def init_params():\n",
    "    w=t.normal(0,1,size=(200,1),requires_grad=True)\n",
    "    b=t.zeros(1,requires_grad=True)\n",
    "    return [w,b]\n",
    "# l2 penalty for weights\n",
    "def l2_penalty(w:t.Tensor):\n",
    "    return t.sum(w.pow(2))/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "def stochastic_gradient_desent(params: t.Tensor, lr, batch_size):\n",
    "    with t.no_grad():\n",
    "        for param in params:\n",
    "            param -= lr*param.grad/batch_size\n",
    "            param.grad.zero_()\n",
    "# training function\n",
    "def train(lambd):\n",
    "    w,b=init_params()\n",
    "    for epoch in range(200):\n",
    "        train_iter = data_iter(1, X[:20], Y[:20])\n",
    "        test_iter = data_iter(1, X[20:], Y[20:])\n",
    "        total_train_loss =[]\n",
    "        total_eval_loss=[]\n",
    "        for x,y in train_iter:\n",
    "            loss = t.pow((y - (t.mm(x, w)+b)), 2).mean()\n",
    "            loss+=lambd*l2_penalty(w)\n",
    "            loss.sum().backward()\n",
    "            stochastic_gradient_desent([w,b],lr=0.003,batch_size=5)\n",
    "            total_train_loss.append(loss.item())\n",
    "        for x,y in test_iter:\n",
    "            #print(x.shape, w.shape, t.mm(x, w).shape)\n",
    "            loss = t.pow((y - (t.mm(x,w)+b)), 2).mean()\n",
    "            total_eval_loss.append(loss.item())\n",
    "            \n",
    "        print(\n",
    "            f\"epoch:{epoch} eval_loss = {np.mean(total_eval_loss)},train_loss = {np.mean(total_train_loss)}\")\n",
    "\n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 eval_loss = 254.72382164686917,train_loss = 88.96197139769792\n",
      "epoch:1 eval_loss = 252.03843209803105,train_loss = 49.58343205804922\n",
      "epoch:2 eval_loss = 250.34449611991644,train_loss = 28.62849868349731\n",
      "epoch:3 eval_loss = 249.2551197373867,train_loss = 17.045214545237833\n",
      "epoch:4 eval_loss = 248.54302406956907,train_loss = 10.411571455466765\n",
      "epoch:5 eval_loss = 248.07687779411674,train_loss = 6.502041579014621\n",
      "epoch:6 eval_loss = 247.73298465620726,train_loss = 4.1438243330456315\n",
      "epoch:7 eval_loss = 247.4740575840324,train_loss = 2.68155178129673\n",
      "epoch:8 eval_loss = 247.26568356154488,train_loss = 1.7585041534155608\n",
      "epoch:9 eval_loss = 247.1365582874813,train_loss = 1.1714977010153234\n",
      "epoch:10 eval_loss = 247.02253701265275,train_loss = 0.7869445707648992\n",
      "epoch:11 eval_loss = 246.925957960971,train_loss = 0.5325349245220423\n",
      "epoch:12 eval_loss = 246.86111817297876,train_loss = 0.36377914382801463\n",
      "epoch:13 eval_loss = 246.80710715883876,train_loss = 0.24967777769206806\n",
      "epoch:14 eval_loss = 246.76652955619153,train_loss = 0.1728103784902487\n",
      "epoch:15 eval_loss = 246.736786280619,train_loss = 0.11992756301478949\n",
      "epoch:16 eval_loss = 246.711552698873,train_loss = 0.08373011008407047\n",
      "epoch:17 eval_loss = 246.6924767910363,train_loss = 0.05850320226090844\n",
      "epoch:18 eval_loss = 246.67526092191227,train_loss = 0.04107760553015396\n",
      "epoch:19 eval_loss = 246.6656946316734,train_loss = 0.02894524257426383\n",
      "epoch:20 eval_loss = 246.65542083746755,train_loss = 0.020461324051575504\n",
      "epoch:21 eval_loss = 246.6475989944581,train_loss = 0.014519485105120111\n",
      "epoch:22 eval_loss = 246.64313125520945,train_loss = 0.010334307604352944\n",
      "epoch:23 eval_loss = 246.63882641339674,train_loss = 0.007385898484244535\n",
      "epoch:24 eval_loss = 246.63403300739824,train_loss = 0.005287169865550822\n",
      "epoch:25 eval_loss = 246.63135826706886,train_loss = 0.0037964987825034767\n",
      "epoch:26 eval_loss = 246.6294302313216,train_loss = 0.00273919061523884\n",
      "epoch:27 eval_loss = 246.62826334077866,train_loss = 0.001976919129328003\n",
      "epoch:28 eval_loss = 246.6276136892475,train_loss = 0.0014334499328015227\n",
      "epoch:29 eval_loss = 246.62697264451535,train_loss = 0.0010418366371595766\n",
      "epoch:30 eval_loss = 246.62673391126097,train_loss = 0.0007579081752453476\n",
      "epoch:31 eval_loss = 246.62700169852005,train_loss = 0.0005534220160711811\n",
      "epoch:32 eval_loss = 246.62678987322374,train_loss = 0.0004051774692641175\n",
      "epoch:33 eval_loss = 246.6271019273624,train_loss = 0.00029805847586032995\n",
      "epoch:34 eval_loss = 246.62753868248313,train_loss = 0.00021916801292718447\n",
      "epoch:35 eval_loss = 246.62787546699866,train_loss = 0.0001613852359622331\n",
      "epoch:36 eval_loss = 246.6282315491326,train_loss = 0.00011927792447750108\n",
      "epoch:37 eval_loss = 246.6283463970572,train_loss = 8.824920428622818e-05\n",
      "epoch:38 eval_loss = 246.62848146462812,train_loss = 6.54607146449493e-05\n",
      "epoch:39 eval_loss = 246.6288144423999,train_loss = 4.866205578881733e-05\n",
      "epoch:40 eval_loss = 246.62908774502574,train_loss = 3.621310610064654e-05\n",
      "epoch:41 eval_loss = 246.62939906017854,train_loss = 2.69658043836718e-05\n",
      "epoch:42 eval_loss = 246.62975611241535,train_loss = 2.011051628092453e-05\n",
      "epoch:43 eval_loss = 246.630070932135,train_loss = 1.5031058231329552e-05\n",
      "epoch:44 eval_loss = 246.63024421911686,train_loss = 1.1259953446796089e-05\n",
      "epoch:45 eval_loss = 246.63044915899636,train_loss = 8.432050432105598e-06\n",
      "epoch:46 eval_loss = 246.63066004682332,train_loss = 6.326860384575639e-06\n",
      "epoch:47 eval_loss = 246.6308310732059,train_loss = 4.75000603490372e-06\n",
      "epoch:48 eval_loss = 246.63096926977857,train_loss = 3.569566866445939e-06\n",
      "epoch:49 eval_loss = 246.6311487578973,train_loss = 2.685639766397685e-06\n",
      "epoch:50 eval_loss = 246.6312662598118,train_loss = 2.019633690331091e-06\n",
      "epoch:51 eval_loss = 246.6313626869209,train_loss = 1.516390371136822e-06\n",
      "epoch:52 eval_loss = 246.63147842645645,train_loss = 1.1465286403833375e-06\n",
      "epoch:53 eval_loss = 246.6315784434229,train_loss = 8.652953708665479e-07\n",
      "epoch:54 eval_loss = 246.6316146265343,train_loss = 6.540208609795429e-07\n",
      "epoch:55 eval_loss = 246.63170826286077,train_loss = 4.927852997771431e-07\n",
      "epoch:56 eval_loss = 246.6317881011963,train_loss = 3.739231562605028e-07\n",
      "epoch:57 eval_loss = 246.63184328248724,train_loss = 2.81766512477688e-07\n",
      "epoch:58 eval_loss = 246.63193071532996,train_loss = 2.138616115310299e-07\n",
      "epoch:59 eval_loss = 246.63195863535628,train_loss = 1.616213275323908e-07\n",
      "epoch:60 eval_loss = 246.6320348100923,train_loss = 1.2232485936403136e-07\n",
      "epoch:61 eval_loss = 246.63205725466833,train_loss = 9.340195279428088e-08\n",
      "epoch:62 eval_loss = 246.63208472494037,train_loss = 7.042507982335522e-08\n",
      "epoch:63 eval_loss = 246.63212724339218,train_loss = 5.346004076089983e-08\n",
      "epoch:64 eval_loss = 246.63216011596845,train_loss = 4.043994261127004e-08\n",
      "epoch:65 eval_loss = 246.6321463565342,train_loss = 3.086585196598879e-08\n",
      "epoch:66 eval_loss = 246.63216729793697,train_loss = 2.3465183493498466e-08\n",
      "epoch:67 eval_loss = 246.63220592599362,train_loss = 1.8189421489150926e-08\n",
      "epoch:68 eval_loss = 246.63223009556532,train_loss = 1.3613729361178217e-08\n",
      "epoch:69 eval_loss = 246.6322268998623,train_loss = 1.018387531456777e-08\n",
      "epoch:70 eval_loss = 246.63226181903855,train_loss = 7.753982416563998e-09\n",
      "epoch:71 eval_loss = 246.63228386122734,train_loss = 5.6612930253441275e-09\n",
      "epoch:72 eval_loss = 246.63228448675946,train_loss = 4.305987968272751e-09\n",
      "epoch:73 eval_loss = 246.6322843456082,train_loss = 3.2530662656682362e-09\n",
      "epoch:74 eval_loss = 246.6322964738868,train_loss = 2.4802281388403013e-09\n",
      "epoch:75 eval_loss = 246.63228357091546,train_loss = 1.883713198619352e-09\n",
      "epoch:76 eval_loss = 246.6322984752804,train_loss = 1.4064539470559633e-09\n",
      "epoch:77 eval_loss = 246.63230379180982,train_loss = 1.145975574851077e-09\n",
      "epoch:78 eval_loss = 246.632308097817,train_loss = 8.67234253160154e-10\n",
      "epoch:79 eval_loss = 246.63230383468792,train_loss = 7.007695340677245e-10\n",
      "epoch:80 eval_loss = 246.63230691630395,train_loss = 5.316541595856705e-10\n",
      "epoch:81 eval_loss = 246.6323304689303,train_loss = 4.1891507207569844e-10\n",
      "epoch:82 eval_loss = 246.6323502959311,train_loss = 3.4162098427881204e-10\n",
      "epoch:83 eval_loss = 246.6323429354653,train_loss = 2.888987854499092e-10\n",
      "epoch:84 eval_loss = 246.6323520980403,train_loss = 2.256126646615897e-10\n",
      "epoch:85 eval_loss = 246.6323332631029,train_loss = 1.7959079223750508e-10\n",
      "epoch:86 eval_loss = 246.63234749563037,train_loss = 1.6587776222043437e-10\n",
      "epoch:87 eval_loss = 246.63235465826466,train_loss = 1.3732367881713615e-10\n",
      "epoch:88 eval_loss = 246.6323526334949,train_loss = 1.1508633906975874e-10\n",
      "epoch:89 eval_loss = 246.63234707210214,train_loss = 1.1592084306344397e-10\n",
      "epoch:90 eval_loss = 246.6323498691432,train_loss = 1.0254177645885321e-10\n",
      "epoch:91 eval_loss = 246.6323592404276,train_loss = 9.291531866822966e-11\n",
      "epoch:92 eval_loss = 246.6323583265394,train_loss = 8.513210553173778e-11\n",
      "epoch:93 eval_loss = 246.63237222610041,train_loss = 7.687027282071712e-11\n",
      "epoch:94 eval_loss = 246.63236989160998,train_loss = 7.510225930734693e-11\n",
      "epoch:95 eval_loss = 246.63236490478738,train_loss = 6.418691845394564e-11\n",
      "epoch:96 eval_loss = 246.63236324368046,train_loss = 6.01331694508045e-11\n",
      "epoch:97 eval_loss = 246.63236707985402,train_loss = 5.367055567334633e-11\n",
      "epoch:98 eval_loss = 246.63237026922405,train_loss = 5.085739485793939e-11\n",
      "epoch:99 eval_loss = 246.6323693488352,train_loss = 4.692683342605308e-11\n",
      "epoch:100 eval_loss = 246.63237807068973,train_loss = 4.454442804197045e-11\n",
      "epoch:101 eval_loss = 246.63237312449144,train_loss = 3.674927185476351e-11\n",
      "epoch:102 eval_loss = 246.63237292863428,train_loss = 3.4920590204212675e-11\n",
      "epoch:103 eval_loss = 246.6323756897077,train_loss = 3.5663698556842593e-11\n",
      "epoch:104 eval_loss = 246.63237138723954,train_loss = 3.361883427893675e-11\n",
      "epoch:105 eval_loss = 246.6323736762628,train_loss = 3.238647006825745e-11\n",
      "epoch:106 eval_loss = 246.63237945806236,train_loss = 3.321038600373472e-11\n",
      "epoch:107 eval_loss = 246.6323788306862,train_loss = 3.5085236278764585e-11\n",
      "epoch:108 eval_loss = 246.63237643068658,train_loss = 2.9699172461594704e-11\n",
      "epoch:109 eval_loss = 246.63237865662202,train_loss = 2.9552284404321674e-11\n",
      "epoch:110 eval_loss = 246.63238393282518,train_loss = 2.2985040433465275e-11\n",
      "epoch:111 eval_loss = 246.63238652909175,train_loss = 2.2085626556755945e-11\n",
      "epoch:112 eval_loss = 246.6323875493929,train_loss = 2.333999538778331e-11\n",
      "epoch:113 eval_loss = 246.63238711308688,train_loss = 2.1655820366117684e-11\n",
      "epoch:114 eval_loss = 246.6323923940584,train_loss = 2.1094097475693464e-11\n",
      "epoch:115 eval_loss = 246.63239268358797,train_loss = 2.0121203488099314e-11\n",
      "epoch:116 eval_loss = 246.63240065913647,train_loss = 2.0432845866669157e-11\n",
      "epoch:117 eval_loss = 246.63240048140287,train_loss = 1.9601327679030777e-11\n",
      "epoch:118 eval_loss = 246.632398555018,train_loss = 1.893398094560128e-11\n",
      "epoch:119 eval_loss = 246.6323988888599,train_loss = 1.633491553826305e-11\n",
      "epoch:120 eval_loss = 246.63239692661912,train_loss = 1.534487970716869e-11\n",
      "epoch:121 eval_loss = 246.63239566449076,train_loss = 1.4123748177941042e-11\n",
      "epoch:122 eval_loss = 246.6323980894126,train_loss = 1.3528676963414643e-11\n",
      "epoch:123 eval_loss = 246.63239660879597,train_loss = 1.2256694444101601e-11\n",
      "epoch:124 eval_loss = 246.63239790102466,train_loss = 1.311735321057883e-11\n",
      "epoch:125 eval_loss = 246.6323963546194,train_loss = 1.3166719277368789e-11\n",
      "epoch:126 eval_loss = 246.6323963428475,train_loss = 1.3997160548673282e-11\n",
      "epoch:127 eval_loss = 246.6324017120339,train_loss = 1.2221120122835049e-11\n",
      "epoch:128 eval_loss = 246.63240066537634,train_loss = 1.1430730147143908e-11\n",
      "epoch:129 eval_loss = 246.63240132337435,train_loss = 1.1284941210665256e-11\n",
      "epoch:130 eval_loss = 246.63239996915684,train_loss = 1.0648447575090091e-11\n",
      "epoch:131 eval_loss = 246.6323994875513,train_loss = 1.0095112419616913e-11\n",
      "epoch:132 eval_loss = 246.6323991362378,train_loss = 9.77741099889018e-12\n",
      "epoch:133 eval_loss = 246.6323994187638,train_loss = 1.0124866396676868e-11\n",
      "epoch:134 eval_loss = 246.6323995904252,train_loss = 9.42613643389878e-12\n",
      "epoch:135 eval_loss = 246.63240048926323,train_loss = 8.86001150918192e-12\n",
      "epoch:136 eval_loss = 246.6324008278176,train_loss = 8.545773984292015e-12\n",
      "epoch:137 eval_loss = 246.63240051787346,train_loss = 8.510069211820071e-12\n",
      "epoch:138 eval_loss = 246.63239655330779,train_loss = 7.545862719393615e-12\n",
      "epoch:139 eval_loss = 246.63239599877969,train_loss = 7.823551702312859e-12\n",
      "epoch:140 eval_loss = 246.63239934379234,train_loss = 7.717147927632784e-12\n",
      "epoch:141 eval_loss = 246.63240002369508,train_loss = 7.389676544289348e-12\n",
      "epoch:142 eval_loss = 246.6324001483619,train_loss = 6.949228865960056e-12\n",
      "epoch:143 eval_loss = 246.6323988447152,train_loss = 6.521837410400355e-12\n",
      "epoch:144 eval_loss = 246.63239862391725,train_loss = 6.535915038352602e-12\n",
      "epoch:145 eval_loss = 246.6323962874152,train_loss = 5.871291126890998e-12\n",
      "epoch:146 eval_loss = 246.63239627787843,train_loss = 6.524635172422411e-12\n",
      "epoch:147 eval_loss = 246.63239812204614,train_loss = 6.081700594517958e-12\n",
      "epoch:148 eval_loss = 246.63240018198266,train_loss = 6.0044290720040475e-12\n",
      "epoch:149 eval_loss = 246.63240481207148,train_loss = 5.833099454843893e-12\n",
      "epoch:150 eval_loss = 246.63240491339937,train_loss = 6.092625189080269e-12\n",
      "epoch:151 eval_loss = 246.63240565488115,train_loss = 6.5461290901791536e-12\n",
      "epoch:152 eval_loss = 246.63240044901147,train_loss = 6.920851565450636e-12\n",
      "epoch:153 eval_loss = 246.6323987991549,train_loss = 6.6146076463380335e-12\n",
      "epoch:154 eval_loss = 246.6323977763392,train_loss = 6.76804046834123e-12\n",
      "epoch:155 eval_loss = 246.63239698478952,train_loss = 7.1399207726696725e-12\n",
      "epoch:156 eval_loss = 246.63239857504144,train_loss = 6.817334370634587e-12\n",
      "epoch:157 eval_loss = 246.632398457285,train_loss = 7.33150085779899e-12\n",
      "epoch:158 eval_loss = 246.63239757562056,train_loss = 6.906685119656419e-12\n",
      "epoch:159 eval_loss = 246.63239549383522,train_loss = 7.414101450831101e-12\n",
      "epoch:160 eval_loss = 246.63239564165474,train_loss = 6.650223600968008e-12\n",
      "epoch:161 eval_loss = 246.63239496454597,train_loss = 6.334920261974464e-12\n",
      "epoch:162 eval_loss = 246.6323964332044,train_loss = 6.4696569282429725e-12\n",
      "epoch:163 eval_loss = 246.6323982785642,train_loss = 6.582810858912769e-12\n",
      "epoch:164 eval_loss = 246.63239611670375,train_loss = 6.673493875564151e-12\n",
      "epoch:165 eval_loss = 246.63239327952266,train_loss = 5.9587767012314606e-12\n",
      "epoch:166 eval_loss = 246.63239305064081,train_loss = 6.038268669794622e-12\n",
      "epoch:167 eval_loss = 246.63239217326046,train_loss = 5.591514924685459e-12\n",
      "epoch:168 eval_loss = 246.63239298149944,train_loss = 5.149468525200707e-12\n",
      "epoch:169 eval_loss = 246.6323919479549,train_loss = 5.077170801837117e-12\n",
      "epoch:170 eval_loss = 246.63239291712642,train_loss = 5.833765588658668e-12\n",
      "epoch:171 eval_loss = 246.6323936228454,train_loss = 5.784738139891221e-12\n",
      "epoch:172 eval_loss = 246.63239200159907,train_loss = 5.2361991478844235e-12\n",
      "epoch:173 eval_loss = 246.6323943094909,train_loss = 5.2424163968223244e-12\n",
      "epoch:174 eval_loss = 246.63239543959497,train_loss = 4.70897643795043e-12\n",
      "epoch:175 eval_loss = 246.63239374682308,train_loss = 4.6824199032013955e-12\n",
      "epoch:176 eval_loss = 246.6324008361995,train_loss = 4.476495736593922e-12\n",
      "epoch:177 eval_loss = 246.63239994093774,train_loss = 4.844290420191743e-12\n",
      "epoch:178 eval_loss = 246.63240153357387,train_loss = 5.335985993337733e-12\n",
      "epoch:179 eval_loss = 246.63240178629755,train_loss = 5.227095319082497e-12\n",
      "epoch:180 eval_loss = 246.63239973351358,train_loss = 5.0682890176401155e-12\n",
      "epoch:181 eval_loss = 246.63239943787457,train_loss = 5.292109979404547e-12\n",
      "epoch:182 eval_loss = 246.6323994462192,train_loss = 5.281984745419965e-12\n",
      "epoch:183 eval_loss = 246.63239909693598,train_loss = 4.67962214117934e-12\n",
      "epoch:184 eval_loss = 246.63240009009837,train_loss = 4.573129548657296e-12\n",
      "epoch:185 eval_loss = 246.6323978844285,train_loss = 4.300458773809357e-12\n",
      "epoch:186 eval_loss = 246.63239673048258,train_loss = 4.301524587912997e-12\n",
      "epoch:187 eval_loss = 246.63239682465792,train_loss = 4.440968599805917e-12\n",
      "epoch:188 eval_loss = 246.6323929718137,train_loss = 4.035159879844929e-12\n",
      "epoch:189 eval_loss = 246.63239422375335,train_loss = 3.974230840253501e-12\n",
      "epoch:190 eval_loss = 246.63239442259072,train_loss = 3.983290260134442e-12\n",
      "epoch:191 eval_loss = 246.63239513784646,train_loss = 4.032006846454994e-12\n",
      "epoch:192 eval_loss = 246.63239464193583,train_loss = 3.699650481803207e-12\n",
      "epoch:193 eval_loss = 246.6323979726434,train_loss = 3.899135354867855e-12\n",
      "epoch:194 eval_loss = 246.63239643007518,train_loss = 3.825061274664865e-12\n",
      "epoch:195 eval_loss = 246.63239673525095,train_loss = 3.910770492165927e-12\n",
      "epoch:196 eval_loss = 246.63239795595408,train_loss = 3.810939237791633e-12\n",
      "epoch:197 eval_loss = 246.6323976674676,train_loss = 4.0059832187577806e-12\n",
      "epoch:198 eval_loss = 246.63239615112542,train_loss = 3.8726676379607914e-12\n",
      "epoch:199 eval_loss = 246.63239957481622,train_loss = 4.0765934031239405e-12\n"
     ]
    }
   ],
   "source": [
    "train(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 eval_loss = 170.2870495343115,train_loss = 272.25671310424804\n",
      "epoch:1 eval_loss = 162.03326724164188,train_loss = 209.4593994140625\n",
      "epoch:2 eval_loss = 154.57629712224008,train_loss = 175.83865356445312\n",
      "epoch:3 eval_loss = 147.54527484223246,train_loss = 155.9456672668457\n",
      "epoch:4 eval_loss = 140.84372130133212,train_loss = 142.63925247192384\n",
      "epoch:5 eval_loss = 134.41331483984365,train_loss = 132.7505168914795\n",
      "epoch:6 eval_loss = 128.2772061723657,train_loss = 124.75498161315917\n",
      "epoch:7 eval_loss = 122.41248211331433,train_loss = 117.90507087707519\n",
      "epoch:8 eval_loss = 116.77649064054644,train_loss = 111.79916038513184\n",
      "epoch:9 eval_loss = 111.37955738157733,train_loss = 106.21666450500489\n",
      "epoch:10 eval_loss = 106.2300901623629,train_loss = 101.02723503112793\n",
      "epoch:11 eval_loss = 101.31281950708478,train_loss = 96.16005935668946\n",
      "epoch:12 eval_loss = 96.61066237484106,train_loss = 91.5693202972412\n",
      "epoch:13 eval_loss = 92.12674142434261,train_loss = 87.22314949035645\n",
      "epoch:14 eval_loss = 87.84535303913988,train_loss = 83.09881706237793\n",
      "epoch:15 eval_loss = 83.7559439532645,train_loss = 79.17955856323242\n",
      "epoch:16 eval_loss = 79.8545273547573,train_loss = 75.4515251159668\n",
      "epoch:17 eval_loss = 76.13495270555373,train_loss = 71.90335845947266\n",
      "epoch:18 eval_loss = 72.5878807519516,train_loss = 68.52469635009766\n",
      "epoch:19 eval_loss = 69.20265681604621,train_loss = 65.30671691894531\n",
      "epoch:20 eval_loss = 65.97340508440975,train_loss = 62.241152381896974\n",
      "epoch:21 eval_loss = 62.89315298329689,train_loss = 59.320312690734866\n",
      "epoch:22 eval_loss = 59.957136594567565,train_loss = 56.537150382995605\n",
      "epoch:23 eval_loss = 57.15762523685174,train_loss = 53.88498363494873\n",
      "epoch:24 eval_loss = 54.48848938065697,train_loss = 51.35751323699951\n",
      "epoch:25 eval_loss = 51.94329342346842,train_loss = 48.948794555664065\n",
      "epoch:26 eval_loss = 49.51692558561597,train_loss = 46.65318775177002\n",
      "epoch:27 eval_loss = 47.204230653499984,train_loss = 44.46533489227295\n",
      "epoch:28 eval_loss = 44.9996215460953,train_loss = 42.380167388916014\n",
      "epoch:29 eval_loss = 42.89760666154034,train_loss = 40.39283962249756\n",
      "epoch:30 eval_loss = 40.89346138358262,train_loss = 38.498745155334475\n",
      "epoch:31 eval_loss = 38.98338840833785,train_loss = 36.693499374389646\n",
      "epoch:32 eval_loss = 37.16229138072427,train_loss = 34.97292423248291\n",
      "epoch:33 eval_loss = 35.42678836802661,train_loss = 33.33305053710937\n",
      "epoch:34 eval_loss = 33.772025401237336,train_loss = 31.770087242126465\n",
      "epoch:35 eval_loss = 32.19474913379192,train_loss = 30.280427169799804\n",
      "epoch:36 eval_loss = 30.691332044030716,train_loss = 28.860622501373292\n",
      "epoch:37 eval_loss = 29.258196824835178,train_loss = 27.507403659820557\n",
      "epoch:38 eval_loss = 27.892170497277256,train_loss = 26.21764793395996\n",
      "epoch:39 eval_loss = 26.58995934615712,train_loss = 24.98836851119995\n",
      "epoch:40 eval_loss = 25.34895248887624,train_loss = 23.81673927307129\n",
      "epoch:41 eval_loss = 24.165697336730954,train_loss = 22.70005226135254\n",
      "epoch:42 eval_loss = 23.037835352463006,train_loss = 21.63573274612427\n",
      "epoch:43 eval_loss = 21.96274932347442,train_loss = 20.62132272720337\n",
      "epoch:44 eval_loss = 20.938093930353062,train_loss = 19.65448417663574\n",
      "epoch:45 eval_loss = 19.96133883512666,train_loss = 18.732979774475098\n",
      "epoch:46 eval_loss = 19.029981681689243,train_loss = 17.85469446182251\n",
      "epoch:47 eval_loss = 18.14240121884257,train_loss = 17.01758680343628\n",
      "epoch:48 eval_loss = 17.296371286143696,train_loss = 16.21974105834961\n",
      "epoch:49 eval_loss = 16.48990986862198,train_loss = 15.459303855895996\n",
      "epoch:50 eval_loss = 15.721119339603757,train_loss = 14.734529304504395\n",
      "epoch:51 eval_loss = 14.988289316933733,train_loss = 14.043743896484376\n",
      "epoch:52 eval_loss = 14.289763684306081,train_loss = 13.385349082946778\n",
      "epoch:53 eval_loss = 13.623841006217699,train_loss = 12.75782914161682\n",
      "epoch:54 eval_loss = 12.989222859219808,train_loss = 12.159732770919799\n",
      "epoch:55 eval_loss = 12.384108707969625,train_loss = 11.589686822891235\n",
      "epoch:56 eval_loss = 11.807400783205084,train_loss = 11.046370553970338\n",
      "epoch:57 eval_loss = 11.257712527417006,train_loss = 10.52853102684021\n",
      "epoch:58 eval_loss = 10.73359688026961,train_loss = 10.034979915618896\n",
      "epoch:59 eval_loss = 10.234100459766559,train_loss = 9.564566278457642\n",
      "epoch:60 eval_loss = 9.757944026438544,train_loss = 9.116217041015625\n",
      "epoch:61 eval_loss = 9.304032848376265,train_loss = 8.688887310028075\n",
      "epoch:62 eval_loss = 8.871378070198043,train_loss = 8.281599521636963\n",
      "epoch:63 eval_loss = 8.45888379127463,train_loss = 7.893412518501282\n",
      "epoch:64 eval_loss = 8.06565128129717,train_loss = 7.523424100875855\n",
      "epoch:65 eval_loss = 7.690822667092602,train_loss = 7.170791959762573\n",
      "epoch:66 eval_loss = 7.333563555233122,train_loss = 6.83468804359436\n",
      "epoch:67 eval_loss = 6.992927565246937,train_loss = 6.514350128173828\n",
      "epoch:68 eval_loss = 6.668173561100412,train_loss = 6.209035015106201\n",
      "epoch:69 eval_loss = 6.358675124892179,train_loss = 5.918031454086304\n",
      "epoch:70 eval_loss = 6.063597002498427,train_loss = 5.640678977966308\n",
      "epoch:71 eval_loss = 5.782320803703914,train_loss = 5.376326489448547\n",
      "epoch:72 eval_loss = 5.514167463835911,train_loss = 5.124375605583191\n",
      "epoch:73 eval_loss = 5.258590553733229,train_loss = 4.884238767623901\n",
      "epoch:74 eval_loss = 5.014900892557052,train_loss = 4.6553617238998415\n",
      "epoch:75 eval_loss = 4.782565401573811,train_loss = 4.437213730812073\n",
      "epoch:76 eval_loss = 4.561089393047732,train_loss = 4.2293034315109255\n",
      "epoch:77 eval_loss = 4.349954683258838,train_loss = 4.031136667728424\n",
      "epoch:78 eval_loss = 4.148650178750104,train_loss = 3.8422624349594114\n",
      "epoch:79 eval_loss = 3.956723916879273,train_loss = 3.662247931957245\n",
      "epoch:80 eval_loss = 3.773806691049249,train_loss = 3.4906721472740174\n",
      "epoch:81 eval_loss = 3.5994158570925356,train_loss = 3.3271419048309325\n",
      "epoch:82 eval_loss = 3.433144189787272,train_loss = 3.171282744407654\n",
      "epoch:83 eval_loss = 3.274644979170698,train_loss = 3.0227277636528016\n",
      "epoch:84 eval_loss = 3.123483016223763,train_loss = 2.8811418652534484\n",
      "epoch:85 eval_loss = 2.979384012988012,train_loss = 2.7461944937705995\n",
      "epoch:86 eval_loss = 2.8420902598745306,train_loss = 2.617573010921478\n",
      "epoch:87 eval_loss = 2.71120728923328,train_loss = 2.494984817504883\n",
      "epoch:88 eval_loss = 2.5863575949688675,train_loss = 2.3781457901000977\n",
      "epoch:89 eval_loss = 2.4673184628336458,train_loss = 2.2667858481407164\n",
      "epoch:90 eval_loss = 2.353901974790497,train_loss = 2.1606436729431153\n",
      "epoch:91 eval_loss = 2.2457432147371583,train_loss = 2.0594830989837645\n",
      "epoch:92 eval_loss = 2.1426244888373187,train_loss = 1.9630643665790557\n",
      "epoch:93 eval_loss = 2.0442374352150363,train_loss = 1.871168965101242\n",
      "epoch:94 eval_loss = 1.9505089005781338,train_loss = 1.783580905199051\n",
      "epoch:95 eval_loss = 1.861123147973558,train_loss = 1.7000972211360932\n",
      "epoch:96 eval_loss = 1.7759282531047937,train_loss = 1.6205341398715973\n",
      "epoch:97 eval_loss = 1.6946926543756853,train_loss = 1.5446962893009186\n",
      "epoch:98 eval_loss = 1.6172297263669315,train_loss = 1.4724132537841796\n",
      "epoch:99 eval_loss = 1.5433809745160396,train_loss = 1.4035272777080536\n",
      "epoch:100 eval_loss = 1.472911774253298,train_loss = 1.337868320941925\n",
      "epoch:101 eval_loss = 1.4057359964774514,train_loss = 1.275285392999649\n",
      "epoch:102 eval_loss = 1.341671110969037,train_loss = 1.2156380891799927\n",
      "epoch:103 eval_loss = 1.2806464314088952,train_loss = 1.1587900340557098\n",
      "epoch:104 eval_loss = 1.2224980539575063,train_loss = 1.104602301120758\n",
      "epoch:105 eval_loss = 1.166980541781318,train_loss = 1.0529620945453644\n",
      "epoch:106 eval_loss = 1.1140235926656805,train_loss = 1.0037394434213638\n",
      "epoch:107 eval_loss = 1.0635415045266927,train_loss = 0.956824105978012\n",
      "epoch:108 eval_loss = 1.0154279276022862,train_loss = 0.9121100246906281\n",
      "epoch:109 eval_loss = 0.9695573703369882,train_loss = 0.8694917500019074\n",
      "epoch:110 eval_loss = 0.9257960123990778,train_loss = 0.8288725197315217\n",
      "epoch:111 eval_loss = 0.8840631832365033,train_loss = 0.790157613158226\n",
      "epoch:112 eval_loss = 0.8442765952323044,train_loss = 0.7532591193914413\n",
      "epoch:113 eval_loss = 0.8063537062350952,train_loss = 0.7180895566940307\n",
      "epoch:114 eval_loss = 0.7702104744012377,train_loss = 0.6845663726329804\n",
      "epoch:115 eval_loss = 0.7357076968320325,train_loss = 0.6526204735040665\n",
      "epoch:116 eval_loss = 0.7027735109249988,train_loss = 0.6221677035093307\n",
      "epoch:117 eval_loss = 0.6714123191972976,train_loss = 0.5931439250707626\n",
      "epoch:118 eval_loss = 0.6414957857471018,train_loss = 0.5654832750558854\n",
      "epoch:119 eval_loss = 0.6129791495235986,train_loss = 0.5391167253255844\n",
      "epoch:120 eval_loss = 0.5857354855055746,train_loss = 0.5139901250600815\n",
      "epoch:121 eval_loss = 0.559780891573464,train_loss = 0.49003738164901733\n",
      "epoch:122 eval_loss = 0.53504307158757,train_loss = 0.467211090028286\n",
      "epoch:123 eval_loss = 0.5114595648899194,train_loss = 0.4454532563686371\n",
      "epoch:124 eval_loss = 0.4889403123833426,train_loss = 0.42471698820590975\n",
      "epoch:125 eval_loss = 0.4674599177296022,train_loss = 0.40494942516088483\n",
      "epoch:126 eval_loss = 0.44699253704820874,train_loss = 0.38611205369234086\n",
      "epoch:127 eval_loss = 0.42745996019628363,train_loss = 0.3681546300649643\n",
      "epoch:128 eval_loss = 0.40884788865805605,train_loss = 0.3510418102145195\n",
      "epoch:129 eval_loss = 0.39106583623521146,train_loss = 0.3347320228815079\n",
      "epoch:130 eval_loss = 0.37412438317856866,train_loss = 0.31918309479951856\n",
      "epoch:131 eval_loss = 0.35793269596384564,train_loss = 0.3043661564588547\n",
      "epoch:132 eval_loss = 0.3425329530775377,train_loss = 0.2902413234114647\n",
      "epoch:133 eval_loss = 0.32781538687882855,train_loss = 0.27678010016679766\n",
      "epoch:134 eval_loss = 0.31377276246857944,train_loss = 0.2639497980475426\n",
      "epoch:135 eval_loss = 0.30039803625111744,train_loss = 0.25172398760914805\n",
      "epoch:136 eval_loss = 0.2876306408802429,train_loss = 0.2400706045329571\n",
      "epoch:137 eval_loss = 0.2754513662117134,train_loss = 0.22896192371845245\n",
      "epoch:138 eval_loss = 0.2638130562014615,train_loss = 0.21837206110358237\n",
      "epoch:139 eval_loss = 0.2527325679654655,train_loss = 0.20827772989869117\n",
      "epoch:140 eval_loss = 0.24216028818534582,train_loss = 0.19866089895367622\n",
      "epoch:141 eval_loss = 0.23206328503152235,train_loss = 0.1894929051399231\n",
      "epoch:142 eval_loss = 0.2224400347692813,train_loss = 0.18075317293405532\n",
      "epoch:143 eval_loss = 0.2132552533322803,train_loss = 0.17242673859000207\n",
      "epoch:144 eval_loss = 0.204479225851136,train_loss = 0.1644881434738636\n",
      "epoch:145 eval_loss = 0.19611886742328466,train_loss = 0.1569223552942276\n",
      "epoch:146 eval_loss = 0.18814103996819767,train_loss = 0.14970849975943565\n",
      "epoch:147 eval_loss = 0.18051885588871755,train_loss = 0.14283412396907808\n",
      "epoch:148 eval_loss = 0.17325006423201558,train_loss = 0.13628508672118186\n",
      "epoch:149 eval_loss = 0.1663324856964573,train_loss = 0.13004073202610017\n",
      "epoch:150 eval_loss = 0.1597287181174761,train_loss = 0.1240882407873869\n",
      "epoch:151 eval_loss = 0.1534175389448683,train_loss = 0.11841569244861602\n",
      "epoch:152 eval_loss = 0.1473858358541932,train_loss = 0.1130098432302475\n",
      "epoch:153 eval_loss = 0.14164260446531443,train_loss = 0.10785582102835178\n",
      "epoch:154 eval_loss = 0.1361685519072489,train_loss = 0.1029420867562294\n",
      "epoch:155 eval_loss = 0.1309344122746552,train_loss = 0.09826084487140178\n",
      "epoch:156 eval_loss = 0.12592172218348424,train_loss = 0.0937976635992527\n",
      "epoch:157 eval_loss = 0.12114190488618988,train_loss = 0.08954509943723679\n",
      "epoch:158 eval_loss = 0.11658944010152936,train_loss = 0.08549212254583835\n",
      "epoch:159 eval_loss = 0.11224980432151277,train_loss = 0.08162714168429375\n",
      "epoch:160 eval_loss = 0.10811216788966249,train_loss = 0.07794227413833141\n",
      "epoch:161 eval_loss = 0.10415385710475675,train_loss = 0.07443382143974304\n",
      "epoch:162 eval_loss = 0.10037154352543438,train_loss = 0.07108567841351032\n",
      "epoch:163 eval_loss = 0.09675518866475613,train_loss = 0.06790052391588688\n",
      "epoch:164 eval_loss = 0.09331896069052163,train_loss = 0.06485635563731193\n",
      "epoch:165 eval_loss = 0.0900207477283402,train_loss = 0.06196112651377916\n",
      "epoch:166 eval_loss = 0.08687851116679667,train_loss = 0.05919726062566042\n",
      "epoch:167 eval_loss = 0.08388050716748693,train_loss = 0.056565481796860696\n",
      "epoch:168 eval_loss = 0.08101121778878223,train_loss = 0.05405581500381231\n",
      "epoch:169 eval_loss = 0.07828702309725713,train_loss = 0.051664155721664426\n",
      "epoch:170 eval_loss = 0.0756817601070361,train_loss = 0.04938467815518379\n",
      "epoch:171 eval_loss = 0.07319103786285268,train_loss = 0.0472094651311636\n",
      "epoch:172 eval_loss = 0.07081694527369109,train_loss = 0.045138715952634814\n",
      "epoch:173 eval_loss = 0.06853331393183908,train_loss = 0.043166295439004895\n",
      "epoch:174 eval_loss = 0.06636778479878558,train_loss = 0.04128429498523474\n",
      "epoch:175 eval_loss = 0.06429041648792917,train_loss = 0.03948990050703287\n",
      "epoch:176 eval_loss = 0.06230555223024567,train_loss = 0.03778199143707752\n",
      "epoch:177 eval_loss = 0.06041669687198009,train_loss = 0.03614781573414803\n",
      "epoch:178 eval_loss = 0.05861097436747514,train_loss = 0.03459569159895182\n",
      "epoch:179 eval_loss = 0.056881640593719564,train_loss = 0.03311719484627247\n",
      "epoch:180 eval_loss = 0.055222977311734665,train_loss = 0.03170530004426837\n",
      "epoch:181 eval_loss = 0.05363444153179614,train_loss = 0.0303592418320477\n",
      "epoch:182 eval_loss = 0.05212328169183707,train_loss = 0.029074579756706954\n",
      "epoch:183 eval_loss = 0.050690192949509764,train_loss = 0.02785371635109186\n",
      "epoch:184 eval_loss = 0.049311585494210705,train_loss = 0.026688160467892887\n",
      "epoch:185 eval_loss = 0.048003997781852374,train_loss = 0.025576675217598675\n",
      "epoch:186 eval_loss = 0.04674849029305811,train_loss = 0.024516419880092143\n",
      "epoch:187 eval_loss = 0.045544493600023085,train_loss = 0.02350947242230177\n",
      "epoch:188 eval_loss = 0.04439343767291156,train_loss = 0.022547030169516803\n",
      "epoch:189 eval_loss = 0.043294258190489925,train_loss = 0.021628750301897526\n",
      "epoch:190 eval_loss = 0.04223755413413301,train_loss = 0.02075492488220334\n",
      "epoch:191 eval_loss = 0.04123940148311249,train_loss = 0.01991898501291871\n",
      "epoch:192 eval_loss = 0.040274842636235916,train_loss = 0.019127920642495154\n",
      "epoch:193 eval_loss = 0.03936139337249187,train_loss = 0.01836571991443634\n",
      "epoch:194 eval_loss = 0.03848524219234605,train_loss = 0.01764608658850193\n",
      "epoch:195 eval_loss = 0.03765148005513765,train_loss = 0.016956709045916795\n",
      "epoch:196 eval_loss = 0.03684563790535322,train_loss = 0.016302708070725203\n",
      "epoch:197 eval_loss = 0.03608352786734031,train_loss = 0.015675028879195453\n",
      "epoch:198 eval_loss = 0.035346420311470866,train_loss = 0.015081152087077498\n",
      "epoch:199 eval_loss = 0.03464027891262958,train_loss = 0.014512235252186655\n"
     ]
    }
   ],
   "source": [
    "train(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由于权重衰减在神经网络优化中很常用， 深度学习框架为了便于我们使用权重衰减， 将权重衰减集成到优化算法中，以便与任何损失函数结合使用。 此外，这种集成还有计算上的好处， 允许在不增加任何额外的计算开销的情况下向算法中添加权重衰减。 由于更新的权重衰减部分仅依赖于每个参数的当前值， 因此优化器必须至少接触每个参数一次。\n",
    "\n",
    "```python\n",
    "def train_concise(wd):\n",
    "    net = nn.Sequential(nn.Linear(num_inputs, 1))\n",
    "    for param in net.parameters():\n",
    "        param.data.normal_()\n",
    "    loss = nn.MSELoss(reduction='none')\n",
    "    num_epochs, lr = 100, 0.003\n",
    "    # 偏置参数没有衰减\n",
    "    trainer = torch.optim.SGD([\n",
    "        {\"params\":net[0].weight,'weight_decay': wd},\n",
    "        {\"params\":net[0].bias}], lr=lr)\n",
    "    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log',\n",
    "                            xlim=[5, num_epochs], legend=['train', 'test'])\n",
    "    for epoch in range(num_epochs):\n",
    "        for X, y in train_iter:\n",
    "            trainer.zero_grad()\n",
    "            l = loss(net(X), y)\n",
    "            l.mean().backward()\n",
    "            trainer.step()\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            animator.add(epoch + 1,\n",
    "                         (d2l.evaluate_loss(net, train_iter, loss),\n",
    "                          d2l.evaluate_loss(net, test_iter, loss)))\n",
    "    print('w的L2范数：', net[0].weight.norm().item())\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "d7d6d563c462dbcb2ee090b6970b42fc638e8eb4a4e6decc12c92a9df43cdf15"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
