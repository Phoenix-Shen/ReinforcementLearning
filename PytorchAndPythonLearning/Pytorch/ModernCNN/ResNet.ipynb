{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# resnet 残差网络\n",
    "随着我们设计了愈来愈深的网络，深刻理解“新添加的层如何提升神经网络的性能”变得至关重要，更重要的是设计网络的能力，在这种网络中，添加层会使网络更具有表现力。\n",
    "\n",
    "何凯明等人提出的ResNet在2015年的ImageNet图像识别挑战赛中夺魁，并深刻影响了后面的深度神经网络的设计。\n",
    "\n",
    "残差网络的核心思想是：每个附加层都应该更容易地包含原始函数作为其元素之一。于是残差快ResBlock便诞生了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Residual(nn.Module):\n",
    "    def __init__(self,input_channels,num_channels,use_1x1conv=False,strides=1)->None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1=nn.Conv2d(input_channels,num_channels,kernel_size=3,padding=1,stride=strides)\n",
    "        self.conv2=nn.Conv2d(num_channels,num_channels,kernel_size=3,padding=1)\n",
    "\n",
    "        # 如果使用1x1conv调整输入或者改变通道数，那么就引入额外的卷积层\n",
    "        if use_1x1conv:\n",
    "            self.conv3 =nn.Conv2d(input_channels,num_channels,kernel_size=1,stride=strides)\n",
    "        else:\n",
    "            self.conv3=None\n",
    "        \n",
    "        self.bn1=nn.BatchNorm2d(num_channels)\n",
    "        self.bn2 =nn.BatchNorm2d(num_channels)\n",
    "    \n",
    "    # 这里是残差块的乾坤所在\n",
    "    def forward(self,X:t.Tensor)->t.Tensor:\n",
    "        Y = relu(self.bn1(self.conv1(X)))\n",
    "        Y=self.bn2(self.conv2(Y))\n",
    "        if self.conv3:\n",
    "            X=self.conv3(X)\n",
    "        # 加法运算\n",
    "        Y=Y+X\n",
    "        return relu(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 6, 6])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 常见的用法\n",
    "blk = Residual(3,3)\n",
    "X = t.rand(4, 3, 6, 6)\n",
    "Y = blk.forward(X)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 6, 3, 3])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 缩减长宽\n",
    "blk = Residual(3, 6, use_1x1conv=True, strides=2)\n",
    "blk.forward(X).shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义ResNet模型\n",
    "resnet 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1 = nn.Sequential(\n",
    "    nn.Conv2d(1,64,kernel_size=7,stride=2,padding=3),\n",
    "    nn.BatchNorm2d(64),nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    ")\n",
    "\n",
    "def res_block(input_channels,num_channels,num_residuals,first_block=False)->nn.Sequential:\n",
    "    blk=[]\n",
    "    for i in range(num_residuals):\n",
    "        if i==0 and not first_block:\n",
    "            blk.append(Residual(input_channels,num_channels,use_1x1conv=True,strides=2))\n",
    "        else:\n",
    "            blk.append(Residual(num_channels,num_channels))\n",
    "    return nn.Sequential(*blk)\n",
    "\n",
    "b2=res_block(64,64,2,first_block=True)\n",
    "b3=res_block(64,128,2)\n",
    "b4=res_block(128,256,2)\n",
    "b5=res_block(256,512,2)\n",
    "\n",
    "net = nn.Sequential(\n",
    "    b1,b2,b3,b4,b5,\n",
    "    nn.AdaptiveAvgPool2d((1,1)),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(512,10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Sequential(\n",
      "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (1): Sequential(\n",
      "    (0): Residual(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): Sequential(\n",
      "    (0): Residual(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): Sequential(\n",
      "    (0): Residual(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): Sequential(\n",
      "    (0): Residual(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): Residual(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (6): Flatten(start_dim=1, end_dim=-1)\n",
      "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 64, 56, 56])\n",
      "Sequential output shape:\t torch.Size([1, 128, 28, 28])\n",
      "Sequential output shape:\t torch.Size([1, 256, 14, 14])\n",
      "Sequential output shape:\t torch.Size([1, 512, 7, 7])\n",
      "AdaptiveAvgPool2d output shape:\t torch.Size([1, 512, 1, 1])\n",
      "Flatten output shape:\t torch.Size([1, 512])\n",
      "Linear output shape:\t torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = t.rand(size=(1, 1, 224, 224))\n",
    "for layer in net:\n",
    "    X = layer(X)\n",
    "    print(layer.__class__.__name__,'output shape:\\t', X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Sequential(\n",
    "  (0): Sequential(\n",
    "    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n",
    "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    (2): ReLU()\n",
    "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "  )\n",
    "  (1): Sequential(\n",
    "    (0): Residual(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    (1): Residual(\n",
    "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (2): Sequential(\n",
    "    (0): Residual(\n",
    "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv3): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2))\n",
    "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    (1): Residual(\n",
    "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (3): Sequential(\n",
    "    (0): Residual(\n",
    "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
    "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    (1): Residual(\n",
    "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (4): Sequential(\n",
    "    (0): Residual(\n",
    "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
    "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
    "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "    (1): Residual(\n",
    "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
    "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "    )\n",
    "  )\n",
    "  (5): AdaptiveAvgPool2d(output_size=(1, 1))\n",
    "  (6): Flatten(start_dim=1, end_dim=-1)\n",
    "  (7): Linear(in_features=512, out_features=10, bias=True)\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torchvision 中的resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "from torch.nn import Flatten,Linear,Conv2d,Module,BatchNorm2d,ReLU,MaxPool2d,Sequential,AdaptiveAvgPool2d\n",
    "from typing import List,Optional\n",
    "from torch import Tensor\n",
    "class Bottleneck(Module):\n",
    "    expansion =4\n",
    "    def __init__(self,in_channels,channels,stride=1,downsample:Optional[Module]=None):\n",
    "        super().__init__()\n",
    "        self.conv1 =Conv2d(in_channels,channels,kernel_size=1,stride=1,bias=False)\n",
    "        self.bn1 = BatchNorm2d(channels)\n",
    "        self.conv2=Conv2d(channels,channels,kernel_size=3,stride=stride,padding=1,bias=False)\n",
    "        self.bn2=BatchNorm2d(channels)\n",
    "        self.conv3=Conv2d(channels,channels*self.expansion,kernel_size=1,stride=1,bias=False)\n",
    "        self.bn3=BatchNorm2d(channels*self.expansion)\n",
    "        self.relu=ReLU(inplace=True)\n",
    "        self.downsample=downsample\n",
    "    \n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "        out=self.relu(self.bn1(self.conv1(x)))\n",
    "        out=self.relu(self.bn2(self.conv2(x)))\n",
    "        out=self.bn3(self.conv3(out))\n",
    "\n",
    "        if self.downsample==None:\n",
    "            identity=x\n",
    "        else:\n",
    "            identity=self.downsample(x)\n",
    "        \n",
    "        out+=identity\n",
    "        out=self.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(Module):\n",
    "    # Generic building func for ResNet-n\n",
    "    def __init__(self,layers:List[int],num_classes=1000)->None:\n",
    "        super().__init__()\n",
    "        self.in_channels =64\n",
    "        self.bottleneck=Bottleneck\n",
    "        # the following layers define stage1( before residual blocks)\n",
    "        self.conv1=Conv2d(3,self.in_channels,kernel_size=7,stride=2,padding=3,bias=False)\n",
    "        self.bn1=BatchNorm2d(self.in_channels)\n",
    "        self.relu=ReLU()\n",
    "        self.maxpool=MaxPool2d(kernel_size=3,stride=2,padding=1)\n",
    "        # the following layers fefine stage 2-5 (residual blocks)\n",
    "        self.layer1=self._make_layer(64,layers[0])\n",
    "        self.layer2=self._make_layer(128,layers[1],stride=2)\n",
    "        self.layer3=self._make_layer(256,layers[2],stride=2)\n",
    "        self.layer4=self._make_layer(512,layers[3],stride=2)\n",
    "        self.avgpool=AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = Linear(512*self.bottleneck.expansion,num_classes)\n",
    "    \n",
    "    def _make_layer(self,channels,num_bottleneck,stride=1):\n",
    "        downsample =Sequential(\n",
    "            Conv2d(self.in_channels,channels*self.bottleneck.expansion,kernel_size=1,stride=stride,bias=False),\n",
    "            BatchNorm2d(channels*self.bottleneck.expansion)\n",
    "        )\n",
    "        layers=[]\n",
    "        layers.append(self.bottleneck(self.in_channels,channels,stride,downsample))\n",
    "        self.in_channels*=self.bottleneck.expansion\n",
    "        if channels!=64:\n",
    "            self.in_channels=int(self.in_channels/2)\n",
    "        for _ in range(1,num_bottleneck):\n",
    "            layers.append(self.bottleneck(self.in_channels,channels))\n",
    "        return Sequential(*layers)\n",
    "\n",
    "    def forward(self,x:Tensor)->Tensor:\n",
    "        out = self.maxpool(self.relu(self.bn1(self.conv1(x))))\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        # global avgpooling func\n",
    "        out =self.avgpool(out)\n",
    "        out=t.flatten(out,1)\n",
    "        out=self.fc(out)\n",
    "        return out\n",
    "    \n",
    "    def ResNet50(num_classess):\n",
    "        return ResNet([3, 4, 6, 3], num_classess)\n",
    "\n",
    "    def ResNet101(num_classess):\n",
    "        return ResNet([3, 4, 23, 3], num_classess)\n",
    "\n",
    "    def ResNet152(num_classess):\n",
    "        return ResNet([3, 8, 36, 3], num_classess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    import torchvision\n",
    "    num_classess = 1000\n",
    "    # Build model structure\n",
    "    resnet152 = ResNet.ResNet152(num_classess)\n",
    "    # Load parameters from pretrained model\n",
    "    pretraind_model_urls = {\n",
    "        'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "        'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "        'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth', }\n",
    "    state_dict = torchvision.models.utils.load_state_dict_from_url(\n",
    "        pretraind_model_urls['resnet152'],\n",
    "        progress=True)\n",
    "    resnet152 = resnet152.load_state_dict(state_dict)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32fe4a0c0b23bf2d0ff7b6ec889b7996b95e9e7ff48467869f67c8fd61e3e485"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
