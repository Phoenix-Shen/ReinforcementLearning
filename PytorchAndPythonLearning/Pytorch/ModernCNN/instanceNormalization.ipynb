{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# instance Normalization\n",
    "对于图像风格迁移这类生成式的任务来说，我们不再关注数据集的“统一规律”，而是要注重像素，每个像素点的信息都是十分重要，于是BN这种每个批量的所有样本都做归一化的算法就不太适用了，因为BN计算归一化统计量的时候考虑了一个批量中所有图片的内容，从而造成了每个样本独特细节的丢失，同理对于LN这类考虑一个样本所有通道的算法来说，可能忽略了不同通道的差异。\n",
    "\n",
    "*IN的算法与BN类似，计算归一化统计量的时候，考虑单个样本，单个通道的所有元素*\n",
    "\n",
    "![](figures/Norm.png)\n",
    "\n",
    "**虽然不是所有的模型都以独立同分布为基础，但是它可以简化常规机器学习模型的训练、提成机器学习模型的预测能力**\n",
    "\n",
    "对比：\n",
    "1. BatchNormalization：由于每个batch的分布不同，会产生Internal Covarivate Shift 的问题，引入BN解决这个问题，对象是对batch的每一层计算平均值和方差，对不同样本的同一个通道的特征做归一化(内部协变量偏移(Internal Covariate Shift)，简单的来说就是输出的分布发生了偏移，和输入的分布不一致；)\n",
    "2. InstanceNormalization: 生成的结果主要依赖于某个实例的时候使用比较好，例如生成式任务等；对象是整个样本本身，对每个channel的特征进行归一化操作\n",
    "3. LayerNormalization: BN容易受到batch_size的影响，而且在RNN这种变长网络中不实用，所以使用LN；计算每一层每一个样本的均值和方差，同一个样本的不同通道做归一化操作\n",
    "\n",
    "## Note \n",
    "InstanceNorm2d and LayerNorm are very similar, but have some subtle differences. InstanceNorm2d is applied on each channel of channeled data like RGB images, but LayerNorm is usually applied on entire sample and often in NLP tasks. Additionally, LayerNorm applies elementwise affine transform, while InstanceNorm2d usually don’t apply affine transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模型优化之Instance Normalization\n",
    "import torch as t\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "def instance_norm(X:Tensor,\n",
    "                    gamma:Tensor,\n",
    "                    beta:Tensor,\n",
    "                    moving_mean:Tensor,\n",
    "                    moving_var:Tensor,\n",
    "                    eps:float,\n",
    "                    momentum:float)->tuple[Tensor,Tensor,Tensor]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Instance Normalization\n",
    "\n",
    "    Parameters:\n",
    "        X: the inputs, it should be tensor with 2 or more dimensions, where the first dimension has \n",
    "        \"batch size\"\n",
    "        gamma: known as \"scale\" in tensorflow , multiply by gamma\n",
    "        beta: known as \"center\" in tensorflow , add by beta\n",
    "        moving_mean: running mean of the dataset\n",
    "        moving_var: running variance of the dataset\n",
    "        eps: a value added to the denominator for numerical stability. Default: 1e-5\n",
    "        momentum: the value used for running_mean and running_var computation. default 0.9\n",
    "    \"\"\"\n",
    "    # 如果在预测模式下，我们直接使用传入的移动平均所得到的均值和方差\n",
    "    if not t.is_grad_enabled():\n",
    "        X_hat = (X-moving_mean)/t.sqrt(moving_var+eps)\n",
    "    else:\n",
    "        # B*C*H*W 所以shape的长度是4，没有全连接层，因为做的是图像\n",
    "        assert len(X.shape)==4\n",
    "        mean = X.mean(dim=(2,3),keepdim=True)\n",
    "        var = t.pow((X-mean),2).mean(dim =(2,3),keepdim=True)\n",
    "        # 训练模式下，使用当前的mean和variance来做标准化\n",
    "        X_hat=(X-mean)/t.sqrt(var+eps)\n",
    "        # 更新移动平均的均值和方差\n",
    "        moving_mean = momentum*moving_mean + (1-momentum)*mean\n",
    "        moving_var=momentum*moving_var+(1-momentum)*var\n",
    "    # 进行缩放和移位，即乘以gamma加上beta\n",
    "    Y = gamma*X_hat+beta\n",
    "    return Y,moving_mean.data,moving_var.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 定义IN模块(nn.instanceNorm2d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InstanceNorm(nn.Module):\n",
    "    def __init__(self,num_featues:int,eps=1e-5,momentum=0.9)->None:\n",
    "        super().__init__()\n",
    "        self.eps = eps\n",
    "        self.momentum = momentum\n",
    "        # 参与求梯度和迭代的拉伸和偏移 scale and center，分别初始化为1和0\n",
    "        self.gamma = nn.Parameter(t.ones((1,num_featues,1,1)))\n",
    "        self.beta=nn.Parameter(t.zeros((1,num_featues,1,1)))\n",
    "        # 非模型参数的变量初始化为0和1\n",
    "        self.moving_mean = t.zeros((1,num_featues,1,1))\n",
    "        self.moving_var = t.ones((1,num_featues,1,1))\n",
    "    \n",
    "    def forward(self,X:Tensor)->Tensor:\n",
    "        if self.moving_mean.device!=X.device:\n",
    "            self.moving_mean=self.moving_mean.to(X.device)\n",
    "            self.moving_var=self.moving_var.to(X.device)\n",
    "        # 保存更新之后的moving_mean和moving_var\n",
    "        Y,self.moving_mean,self.moving_var=instance_norm(X,self.gamma,self.beta,self.moving_mean,self.moving_var,self.eps,self.momentum)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 看看效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X = t.arange(0, 27*2, 1, dtype=t.float32).reshape(2, 3, 3, 3)\n",
    "X=t.randn((2, 3, 3, 3),requires_grad=False)\n",
    "X.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.2945, -1.5122,  1.0822],\n",
       "          [ 0.0144, -0.8685, -0.2099],\n",
       "          [ 1.9219,  0.8777, -1.8266]],\n",
       "\n",
       "         [[-0.3839,  0.2849, -0.5585],\n",
       "          [-0.3494, -0.3829,  0.0442],\n",
       "          [-0.0484,  0.7183,  0.3327]],\n",
       "\n",
       "         [[ 0.0616, -0.2440, -2.1194],\n",
       "          [ 0.5784, -0.3306, -0.4595],\n",
       "          [-0.1795,  1.0353, -1.9222]]],\n",
       "\n",
       "\n",
       "        [[[ 0.2257, -0.6211, -0.5136],\n",
       "          [ 1.1761, -0.2628, -0.1389],\n",
       "          [ 0.2762, -1.4807,  0.3589]],\n",
       "\n",
       "         [[-0.1493,  0.3094, -0.3921],\n",
       "          [-0.8907,  0.7273, -0.7800],\n",
       "          [ 0.2006,  1.0684,  0.8334]],\n",
       "\n",
       "         [[-0.7727,  0.9414,  0.9452],\n",
       "          [-1.2443,  1.2667,  0.7676],\n",
       "          [ 1.0871,  0.6903, -0.6807]]]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_pytorch = nn.InstanceNorm2d(3)\n",
    "in_mymethod = InstanceNorm(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1761, -1.2275,  1.0127],\n",
       "          [ 0.0907, -0.6717, -0.1030],\n",
       "          [ 1.7378,  0.8362, -1.4991]],\n",
       "\n",
       "         [[-0.8684,  0.8112, -1.3068],\n",
       "          [-0.7817, -0.8659,  0.2068],\n",
       "          [-0.0259,  1.8995,  0.9312]],\n",
       "\n",
       "         [[ 0.4704,  0.1574, -1.7627],\n",
       "          [ 0.9995,  0.0688, -0.0632],\n",
       "          [ 0.2234,  1.4673, -1.5608]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4752, -0.7274, -0.5747],\n",
       "          [ 1.8248, -0.2185, -0.0425],\n",
       "          [ 0.5469, -1.9480,  0.6643]],\n",
       "\n",
       "         [[-0.3792,  0.3102, -0.7442],\n",
       "          [-1.4937,  0.9383, -1.3273],\n",
       "          [ 0.1467,  1.4511,  1.0979]],\n",
       "\n",
       "         [[-1.2332,  0.6779,  0.6821],\n",
       "          [-1.7590,  1.0406,  0.4841],\n",
       "          [ 0.8403,  0.3979, -1.1306]]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_pytorch.forward(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1761, -1.2275,  1.0127],\n",
       "          [ 0.0907, -0.6717, -0.1030],\n",
       "          [ 1.7378,  0.8362, -1.4991]],\n",
       "\n",
       "         [[-0.8684,  0.8112, -1.3068],\n",
       "          [-0.7817, -0.8659,  0.2068],\n",
       "          [-0.0259,  1.8995,  0.9312]],\n",
       "\n",
       "         [[ 0.4704,  0.1574, -1.7627],\n",
       "          [ 0.9995,  0.0688, -0.0632],\n",
       "          [ 0.2234,  1.4673, -1.5608]]],\n",
       "\n",
       "\n",
       "        [[[ 0.4752, -0.7274, -0.5747],\n",
       "          [ 1.8248, -0.2185, -0.0425],\n",
       "          [ 0.5469, -1.9480,  0.6643]],\n",
       "\n",
       "         [[-0.3792,  0.3102, -0.7442],\n",
       "          [-1.4937,  0.9383, -1.3273],\n",
       "          [ 0.1467,  1.4511,  1.0979]],\n",
       "\n",
       "         [[-1.2332,  0.6779,  0.6821],\n",
       "          [-1.7590,  1.0406,  0.4841],\n",
       "          [ 0.8403,  0.3979, -1.1306]]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_mymethod.forward(X)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32fe4a0c0b23bf2d0ff7b6ec889b7996b95e9e7ff48467869f67c8fd61e3e485"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
