{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 需要输出概率的情况下，我们使用Softmax回归问题，它能够输出一个数组，代表每个选项的概率\n",
    "如 [0.1,0,2,0.3,0.4]\n",
    "- 使用杜热编码来表示分类数据：它是一个向量，它的分量和类别一样多，类别对应的分量设置为1，其他所有的分量，例如猫狗鸡三分类问题中，猫为(1,0,0)\n",
    "- 为了解决线性模型的分类问题，需要和输出一样多的仿射函数（affine function）对于面的问题，可以表示为\n",
    "```\n",
    "o1=x1w11+x2w12+x3w13+x4w14+b1\n",
    "o2=x1w21+x2w22+x3w23+x4w24+b2\n",
    "o3=x1w31+x2w32+x3w33+x4w34+b1\n",
    "```\n",
    "一共需要（输入特征数*输出概率的数量）个参数\n",
    "\n",
    "# 全连接层的参数开销\n",
    "从上面的例子中，我们可以看到全连接层的参数开销是(O(输入特征数*输出数))，在实践中可能很高，但是可以减少到原来的1/n。\n",
    "\n",
    "# softmax运算\n",
    "我们要限制输出的概率之和为1，但是不能够规范化输出o1,o2,o3，而且输出可能为负值，所以我们需要一个训练目标，来鼓励模型精准地估计概率。\n",
    "\n",
    "y=softmax(o)，其中 yi= exp(oi)/sigema k(exp(ok))\n",
    "\n",
    "他是一个非线性的函数，但是softmax回归的输出仍然是由输入特征的仿射变换来确定的，所以还是一个线性模型。\n",
    "\n",
    "# 损失函数\n",
    "- 对数似然函数：找到一组估计值，使得未知参数取该估计值时，观察值以最大概率出现\n",
    "\n",
    "设X为离散型随机变量，P(X=xk)=p(xk,theta)其中theta是待估计参数，那么X1=x1,X2=x2....的概率为\n",
    "P(X1=x1,X2=x2,X3=x3....)=所有的p(xk,theta)之积，记作L（theta），大多数情况求个对数，将乘法换成加法，方便很多。\n",
    "\n",
    "当似然函数取最大值的时候，说明这组参数一定程度上非常贴合所给的数据分布，预测的值域真实值很接近，损失函数较小。\n",
    "\n",
    "# 信息的熵\n",
    "信息的熵是信息内容的量化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
