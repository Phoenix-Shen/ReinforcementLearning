{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 需要输出概率的情况下，我们使用Softmax回归问题，它能够输出一个数组，代表每个选项的概率\n",
    "如 [0.1,0,2,0.3,0.4]\n",
    "- 使用杜热编码来表示分类数据：它是一个向量，它的分量和类别一样多，类别对应的分量设置为1，其他所有的分量，例如猫狗鸡三分类问题中，猫为(1,0,0)\n",
    "- 为了解决线性模型的分类问题，需要和输出一样多的仿射函数（affine function）对于面的问题，可以表示为\n",
    "```\n",
    "o1=x1w11+x2w12+x3w13+x4w14+b1\n",
    "o2=x1w21+x2w22+x3w23+x4w24+b2\n",
    "o3=x1w31+x2w32+x3w33+x4w34+b1\n",
    "```\n",
    "一共需要（输入特征数*输出概率的数量）个参数\n",
    "\n",
    "# 全连接层的参数开销\n",
    "从上面的例子中，我们可以看到全连接层的参数开销是(O(输入特征数*输出数))，在实践中可能很高，但是可以减少到原来的1/n。\n",
    "\n",
    "# softmax运算\n",
    "我们要限制输出的概率之和为1，但是不能够规范化输出o1,o2,o3，而且输出可能为负值，所以我们需要一个训练目标，来鼓励模型精准地估计概率。\n",
    "\n",
    "y=softmax(o)，其中 yi= exp(oi)/sigema k(exp(ok))\n",
    "\n",
    "他是一个非线性的函数，但是softmax回归的输出仍然是由输入特征的仿射变换来确定的，所以还是一个线性模型。\n",
    "\n",
    "# 损失函数\n",
    "- 对数似然函数：找到一组估计值，使得未知参数取该估计值时，观察值以最大概率出现\n",
    "\n",
    "设X为离散型随机变量，P(X=xk)=p(xk,theta)其中theta是待估计参数，那么X1=x1,X2=x2....的概率为\n",
    "P(X1=x1,X2=x2,X3=x3....)=所有的p(xk,theta)之积，记作L（theta），大多数情况求个对数，将乘法换成加法，方便很多。\n",
    "\n",
    "当似然函数取最大值的时候，说明这组参数一定程度上非常贴合所给的数据分布，预测的值域真实值很接近，损失函数较小。\n",
    "\n",
    "# 信息的熵\n",
    "信息的熵是信息内容的量化，我们定义分布P的熵（entropy）为H[p]=Σj -P(j)log(P(j))\n",
    "\n",
    "# 模型预测和评估\n",
    "在训练softmax回归模型后，给出任何样本特征，我们可以预测每个输出类别的概率。 通常我们使用预测概率最高的类别作为输出类别。 如果预测与实际类别（标签）一致，则预测是正确的。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import torch as t\n",
    "from pltutils import *\n",
    "import numpy as np\n",
    "from torch.utils import data\n",
    "from torchvision import transforms\n",
    "import torchvision as tv\n",
    "use_svg_display()\n",
    "\n",
    "#定义对数据集进行的操作\n",
    "transform=transforms.ToTensor()\n",
    "minst_train = tv.datasets.FashionMNIST(\n",
    "    \"./dataset\",train=True,transform=transform,download=True)\n",
    "minst_test = tv.datasets.FashionMNIST(\n",
    "    \"./dataset\", train=False, transform=transform, download=True)\n",
    "len(minst_train), len(minst_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "data_,label_=minst_train[0]\n",
    "print(data_.shape)\n",
    "print(label_)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "32fe4a0c0b23bf2d0ff7b6ec889b7996b95e9e7ff48467869f67c8fd61e3e485"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
