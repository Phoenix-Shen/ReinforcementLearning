# DPPO

- the multi-thread version of Proximal Policy Optimization

- the code of PPO can be seen [there](<../ProximalPolicyOptimization(PPO)>)
